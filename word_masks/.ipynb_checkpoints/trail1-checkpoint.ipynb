{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b337352-ab0d-4965-84cd-09c86bb7fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (4.46.1)\n",
      "Requirement already satisfied: torch in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: pandas in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (2.2.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers torch pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19a2c2d-44fd-46ef-ac2a-7b1232fd695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf03e332-2be6-4851-8c67-7a5daf11032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a150f80-2c78-410d-a6b7-bd0fe9aea5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "fake_data_path = \"E:/Computer Science/Computer Science Fall 2024/Information Retrival/Jupter/Jupyter_Practice/Fake.csv\"\n",
    "real_data_path = \"E:/Computer Science/Computer Science Fall 2024/Information Retrival/Jupter/Jupyter_Practice/True.csv\"\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(fake_data_path, real_data_path):\n",
    "    fake_data = pd.read_csv(fake_data_path)\n",
    "    real_data = pd.read_csv(real_data_path)\n",
    "\n",
    "    # Add target labels\n",
    "    fake_data['label'] = 0  # Fake news\n",
    "    real_data['label'] = 1  # Real news\n",
    "\n",
    "    # Concatenate and shuffle\n",
    "    data = pd.concat([fake_data, real_data], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc274db2-a881-4d76-8fd1-92e4e4f6c5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   title  \\\n",
       " 36335   Billy Joel Just Publicly Humiliated The Donal...   \n",
       " 12384  Swiss dismiss ETA activist's asylum bid, but s...   \n",
       " 24419   SHAME: Desperate Rubio Repeatedly Tries To Pi...   \n",
       " 24740  North Korea meeting seeks 'better ideas' to so...   \n",
       " 27039   Watch The Moment A White Teacher Gets SCHOOLE...   \n",
       " \n",
       "                                                     text    subject  \\\n",
       " 36335  Billy Joel made a fool of Donald Trump this we...       News   \n",
       " 12384  ZURICH (Reuters) - A Swiss federal court has d...  worldnews   \n",
       " 24419  In what can only be seen as the worst attempt ...       News   \n",
       " 24740  OTTAWA (Reuters) - An international meeting in...  worldnews   \n",
       " 27039  A brilliant moment where a high school student...       News   \n",
       " \n",
       "                      date  label  \n",
       " 36335        May 29, 2016      0  \n",
       " 12384   December 1, 2017       1  \n",
       " 24419   February 14, 2016      0  \n",
       " 24740  November 29, 2017       1  \n",
       " 27039    February 9, 2016      0  ,\n",
       "                                                    title  \\\n",
       " 22216  Kenya opposition supporters urged to boycott t...   \n",
       " 27917  Texas politician slammed for tweet sent after ...   \n",
       " 25007  Hong Kong seeks law banning booing of China's ...   \n",
       " 1377   Mexican human rights group mulls legal action ...   \n",
       " 32476  Trump asked Putin if allegations of Russian me...   \n",
       " \n",
       "                                                     text       subject  \\\n",
       " 22216  NAIROBI (Reuters) - Kenya s opposition coaliti...     worldnews   \n",
       " 27917  AUSTIN, Texas (Reuters) - The office of Texas ...  politicsNews   \n",
       " 25007  HONG KONG (Reuters) - Hong Kong will try to en...     worldnews   \n",
       " 1377   MEXICO CITY (Reuters) - Mexico s National Huma...     worldnews   \n",
       " 32476  MOSCOW (Reuters) - Donald Trump directly asked...  politicsNews   \n",
       " \n",
       "                      date  label  \n",
       " 22216   November 3, 2017       1  \n",
       " 27917      June 12, 2016       1  \n",
       " 25007   November 1, 2017       1  \n",
       " 1377   December 17, 2017       1  \n",
       " 32476  November 12, 2017       1  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = load_and_preprocess_data(fake_data_path, real_data_path)\n",
    "train_data.head(), test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a09ba1-d76a-454c-87a4-405b1a842413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch Dataset for news classification\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff2d38-c409-4225-bc23-30133921cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model for DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "model = model.to(device)\n",
    "print('DistilBERT model loaded and moved to', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c4d07-a84f-4e07-8348-8e98b79a4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Datasets\n",
    "train_dataset = NewsDataset(train_data, tokenizer)\n",
    "test_dataset = NewsDataset(test_data, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094932b5-de9b-491d-877f-1dd1eb490506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader setup for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8da48e-1aa5-4aea-8d2c-9007eee6f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train_model(model, train_loader, optimizer, scheduler, num_epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2433fa3-4ec5-4fac-995d-2b860cbaffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\\n\", classification_report(true_labels, predictions))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b72c55-9244-46e3-b247-70b018cc7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and scheduler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436455ee-bf2f-4ccc-a4de-31f34d6ef21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, optimizer, scheduler, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc672b8-786f-4376-aeb0-f1c9860dba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298c9f0c-fb24-4bfb-b02d-ed399530fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, f1_score, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime  \n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09f40148-489b-4e7c-a36b-78ac6f8eea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0171582a-6f72-4cec-a0d7-da2e407d6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dd470f2-dbfd-4a4d-83cb-52fe5086f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "DISTILBERT_PATH = './model/distilbert'\n",
    "LLAMA_PATH = './model/llama'\n",
    "OPT_PATH = './model/opt'\n",
    "GPT2_PATH = './model/gpt2'\n",
    "ELECTRA_PATH = './model/electra'\n",
    "\n",
    "# Create model directories if they don't exist\n",
    "os.makedirs(DISTILBERT_PATH, exist_ok=True)\n",
    "os.makedirs(ELECTRA_PATH, exist_ok=True)\n",
    "os.makedirs(LLAMA_PATH, exist_ok=True)\n",
    "os.makedirs(OPT_PATH, exist_ok=True)\n",
    "os.makedirs(GPT2_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define directories for saving outputs\n",
    "OUTPUT_DIR = './outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "COMBINATIONS = ['distilbert_gpt2', 'distilbert_llama', 'distilbert_opt']\n",
    "for combination in COMBINATIONS:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, combination), exist_ok=True)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb8a9689-c2fe-4d06-8d8c-e191cafc09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fake_data = pd.read_csv(\"./data/Fake.csv\")\n",
    "real_data = pd.read_csv(\"./data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "144cada2-d5e6-4859-8c2c-629228c6da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and labeling\n",
    "fake_data[\"label\"] = \"fake\"\n",
    "real_data[\"label\"] = \"real\"\n",
    "final_data = pd.concat([fake_data, real_data])\n",
    "final_data = final_data.sample(frac=1).reset_index(drop=True)\n",
    "final_data['label'] = final_data['label'].map({'real': 1, 'fake': 0})\n",
    "\n",
    "# Combine title and text fields into a single text column for processing\n",
    "final_data['text'] = final_data['title'] + \" \" + final_data['text']\n",
    "final_data = final_data[['text', 'label']]\n",
    "\n",
    "# NLTK preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove content in brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c70d3818-5946-4d27-ad7f-f31a8ecb9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply NLTK preprocessing\n",
    "final_data[\"text\"] = final_data[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9d680b1-3af7-4f88-b766-718d4f85f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  watch clueless antitrump “protesters” asked th...      0\n",
      "1  brother famous actress pretend black get med s...      0\n",
      "2  judge jeanine pirro rip lying medium “in cahoo...      0\n",
      "3  senate pass puerto rico debt bill sends obama ...      1\n",
      "4  obama face immigration hurdle even win high co...      1\n"
     ]
    }
   ],
   "source": [
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13bbb8d8-1558-4014-8a16-0bec8e188dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.drop([\"subject\",\"date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dc96b86-85ec-446c-b03f-2854979bc9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    23481\n",
       "1    21417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94cea9a1-43d5-4dfe-804f-7e83c264d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3417ff3-e7c2-4013-bc20-6b43f151d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19119</th>\n",
       "      <td>chagrined antitrump republican seek recruit th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>donald trump infuriates woman disgusting ‘rape...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29259</th>\n",
       "      <td>britain accelerates brexit plan divorce talk a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30148</th>\n",
       "      <td>russia say trump aggressive stance iran doomed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25007</th>\n",
       "      <td>breaking trump pick private sector titan trade...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37972</th>\n",
       "      <td>factbox zika virus causing alarm global health...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19003</th>\n",
       "      <td>former navy seal harvard grad “bodyslams” fake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29701</th>\n",
       "      <td>greek march mark 1973 student revolt junta cla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33928</th>\n",
       "      <td>donald trump jr say dad beat refusing get coke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22516</th>\n",
       "      <td>trump tied clinton utah lewd remark video poll...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "19119  chagrined antitrump republican seek recruit th...      1\n",
       "9894   donald trump infuriates woman disgusting ‘rape...      0\n",
       "29259  britain accelerates brexit plan divorce talk a...      1\n",
       "30148  russia say trump aggressive stance iran doomed...      1\n",
       "25007  breaking trump pick private sector titan trade...      0\n",
       "37972  factbox zika virus causing alarm global health...      1\n",
       "19003  former navy seal harvard grad “bodyslams” fake...      0\n",
       "29701  greek march mark 1973 student revolt junta cla...      1\n",
       "33928  donald trump jr say dad beat refusing get coke...      0\n",
       "22516  trump tied clinton utah lewd remark video poll...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2de25b95-191a-4bf2-b257-bbd58a4b5b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'law obama go around congress place gag order reporting firearm ultimate gun control end game barack obama regime periodon june 1 breitbart news reported obama spring 2015 unified agenda gun control measure contained therein passed executive fiatsince time representative like rep thomas massie rky91 rky4th placed rider doj appropriation bill stop portion executive gun control push track nraila revealing obama administration working behind scene stifle reporting firearmsfrom nrailaeven news report highlighting gun control provision administration unified agenda regulatory objective obama state department quietly moving ahead proposal could censor online speech related firearmshow happenlike administration reworking international traffic arm regulation itar one many thing regulated itar technical data tied defense article includes limited detailed design development production manufacturing information ammunition firearmsmore specifically kind technical data would blueprint drawing photograph plan instruction documentation related ammunition firearmswhile itar regulation concern past far constraining limiting material posted publicly available website within current state department arguing anything published online generallyaccessible location essentially exported simply virtue posted therefore purview itarmoreover last week state department put forth proposal clarifying handle release containing technical data posted online otherwise distributed public domain ultimately proposal would require releasing technical data ammunition firearm first seek government approvalhere nraila summed upthe proposal would institute massive new prior restraint free speech release would require authorization government occurred cumbersome timeconsuming process obtaining authorization moreover would make online communication certain technical aspect firearm ammunition essentially impossiblepublic comment proposed change itar accepted august 3 2015 submit comment regulationsgov email ddtcpubliccommentsstategov subject line indicating comment concern itar amendment revision definition data transmission storage via breitbart news'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.text[36709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0509408d-d1e7-4268-b658-c12bf7a8872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# 0. GPU or CPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1989a076-7003-445e-9e7d-18284364e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenization function\n",
    "def tokenize_data(texts, tokenizer, max_length=64):\n",
    "    if isinstance(texts, list):\n",
    "        texts = [str(text) if text is not None else \"\" for text in texts]\n",
    "    else:\n",
    "        texts = str(texts) if texts is not None else \"\"\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c0513cc-6150-45ab-86a9-ba19052cf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and preprocess datasets for training\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    final_data[\"text\"].tolist(),\n",
    "    final_data[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=final_data[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8af52e83-f1ff-494e-9596-ef9cf8b0a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model_dir(base_path):\n",
    "    model_dirs = glob.glob(os.path.join(base_path, \"*\"))\n",
    "    if not model_dirs:\n",
    "        return None\n",
    "    latest_dir = max(model_dirs, key=os.path.getmtime)\n",
    "    return latest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84d227-7af9-48fd-99f0-00d53e7dbab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c0501f-45b5-45b7-81e8-92844a6a8dbf",
   "metadata": {},
   "source": [
    "### Train Distilbert Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5756ffe-4eac-4556-8840-856e363c8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train DistilBERT-based model\n",
    "def train_distilbert(train_texts, train_labels, test_texts, test_labels, epochs, output_dir='./model/distilbert'):\n",
    "    print(\"Training DistilBERT\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
    "\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels)\n",
    "    })\n",
    "\n",
    "    test_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels)\n",
    "    })\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,  # Smaller batch size for CPU\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,  # Higher accumulation for larger effective batch size\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,  # Slightly higher learning rate to reduce epochs\n",
    "        logging_dir='./distilbert_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        no_cuda=True,  # Ensure CPU-only\n",
    "        bf16=False,  # Set to True if CPU supports bfloat16\n",
    "        dataloader_num_workers=4  # Use multiple workers for data loading\n",
    "    )\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55ccea91-fd26-4d8c-8c15-004a9e0da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilBERT model\n",
    "def load_distilbert():\n",
    "    print(f\"Loading DistilBERT model from {DISTILBERT_PATH}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(DISTILBERT_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(DISTILBERT_PATH)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cfd1c-d455-4476-aea3-033adc4f75da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a226ad-4604-4250-abb6-af54a0c65784",
   "metadata": {},
   "source": [
    "### Train GPT-2 Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a0971f7-15ed-4664-8a42-fff2cb88c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt2(train_texts, test_texts, epochs):\n",
    "    print(\"Training GPT-2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a padding token, use EOS token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenizer(train_texts, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "    test_encodings = tokenizer(test_texts, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "    # Set the labels to be the same as input IDs for causal language modeling\n",
    "    train_encodings['labels'] = train_encodings['input_ids'].clone()\n",
    "    test_encodings['labels'] = test_encodings['input_ids'].clone()\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(GPT2_PATH, f\"gpt2_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./gpt2_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU-only\n",
    "        fp16=torch.cuda.is_available(),  # Enable fp16 (mixed precision) if using CUDA\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer with both train and eval datasets\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset  # Add eval dataset for evaluation\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"GPT-2 model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "604ec3b1-9f9a-4f09-afff-01dd8f0df3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest GPT-2 model\n",
    "def load_gpt2():\n",
    "    latest_dir = get_latest_model_dir(GPT2_PATH)\n",
    "    if latest_dir:\n",
    "        print(f\"Loading GPT-2 model from {latest_dir}\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(latest_dir).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_dir)\n",
    "        return model, tokenizer\n",
    "    else:\n",
    "        print(\"No pre-trained GPT-2 model found.\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1fbf2-201b-4f88-af71-37569dcdb188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0074e863-3e66-413b-8883-477a7afab7f0",
   "metadata": {},
   "source": [
    "### Train ELECTRA Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1509265a-3b07-4168-8206-316a11d996a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRA Training Function\n",
    "def train_electra(train_texts, train_labels, test_texts, test_labels, epochs):\n",
    "    print(\"Training ELECTRA\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=2).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels, dtype=torch.long)  # Corrected to use train_labels\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels, dtype=torch.long)  # Corrected to use test_labels\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(ELECTRA_PATH, f\"electra_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./electra_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"ELECTRA model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c44f0b6f-840c-4469-8c61-d9b341846504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest ELECTRA model\n",
    "def load_electra():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(ELECTRA_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ELECTRA_PATH)\n",
    "    print(f\"ELECTRA model loaded from {ELECTRA_PATH}\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f51431-a57e-4a5a-85d6-aab19c4b1ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826c53f2-cb56-4719-8075-e1a730c9994f",
   "metadata": {},
   "source": [
    "### Train LLama Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e89e989-aa53-481a-a911-6fde2fa29315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLAMA Training Function\n",
    "# Public LLAMA model training function\n",
    "def train_llama(train_texts, test_texts, epochs):\n",
    "    # print(\"Training LLAMA\")\n",
    "    # token = \"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\"  # Replace with your actual Hugging Face token\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "    # model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(LLAMA_PATH, f\"llama_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./llama_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        bf16=False,  # Set to False for CPU training\n",
    "        dataloader_num_workers=3\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"LLAMA model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c852e8f4-05d6-4a2f-a385-06b7d21abca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest LLAMA model\n",
    "def load_llama():\n",
    "    model = AutoModelForCausalLM.from_pretrained(LLAMA_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "    print(f\"LLAMA model loaded from {LLAMA_PATH}\")\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34191d-9902-4a4f-b578-1578fd6b1757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70e9ff5-f77c-4d95-87d5-1cb935b5c324",
   "metadata": {},
   "source": [
    "### Train Opt Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d828fab4-f043-4c69-a0f7-52c62424fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPT Training Function\n",
    "def train_opt(train_texts, test_texts, epochs):\n",
    "    print(\"Training OPT\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\")  # Model stays on CPU\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(OPT_PATH, f\"opt_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./opt_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        bf16=False,  # bf16 is only for GPU, so set this to False\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"OPT model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f577c75e-489d-45ae-89f3-6715ae4c09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest OPT model\n",
    "def load_opt():\n",
    "    model = AutoModelForCausalLM.from_pretrained(OPT_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(OPT_PATH)\n",
    "    print(f\"OPT model loaded from {OPT_PATH}\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab65af0-b857-4c08-ac67-1980bab6779d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ee2113-da86-4ce2-8efe-3d9fd7092750",
   "metadata": {},
   "source": [
    "## Hybrid Detection Models for Robust Detection of Disinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30c031f3-b6bb-42dd-9d60-0910c397c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Model with DistilBERT and GPT-2\n",
    "def detect_with_distilbert_gpt2(text, bert_model, bert_tokenizer, gpt_model, gpt_tokenizer, similarity_threshold=0.77):\n",
    "    # Text preprocessing\n",
    "    text = text_preprocessing(text)\n",
    "    # BERT prediction\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    # GPT-2 text generation\n",
    "    gpt_inputs = gpt_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    gpt_outputs = gpt_model.generate(gpt_inputs, max_length=100, pad_token_id=gpt_tokenizer.eos_token_id)\n",
    "    generated_text = gpt_tokenizer.decode(gpt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # BERT prediction on GPT-2-generated text\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]  # [CLS] token embedding\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67832b1f-30a3-4740-8899-4d70f861967c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ae1e892-9bf1-4b64-b3b5-e1ed17a0860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Function for DistilBERT + LLAMA\n",
    "def detect_with_distilbert_llama(text, bert_model, bert_tokenizer, llama_model, llama_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    llama_inputs = llama_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    llama_outputs = llama_model.generate(llama_inputs, max_length=100, pad_token_id=llama_tokenizer.eos_token_id)\n",
    "    generated_text = llama_tokenizer.decode(llama_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827af81-862f-43ac-ae2d-a15ea54be57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "342fe109-737f-49ee-998f-34f0f9071707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Function for DistilBERT + OPT\n",
    "def detect_with_distilbert_opt(text, bert_model, bert_tokenizer, opt_model, opt_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    opt_inputs = opt_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    opt_outputs = opt_model.generate(opt_inputs, max_length=100, pad_token_id=opt_tokenizer.eos_token_id)\n",
    "    generated_text = opt_tokenizer.decode(opt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6b7c-eb09-41a4-9670-15c53b449972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e375de8f-c18d-4824-b869-6c7fd0fcb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Function for DistilBERT + ELECTRA\n",
    "def detect_with_distilbert_electra(text, bert_model, bert_tokenizer, electra_model, electra_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    electra_inputs = electra_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    electra_outputs = electra_model(electra_inputs['input_ids'], attention_mask=electra_inputs['attention_mask'])\n",
    "    generated_text = electra_tokenizer.decode(electra_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5aa3b-ac24-414e-8afc-ce44d4e54417",
   "metadata": {},
   "source": [
    "## Train Models, distilbert, Gpt-2, LLama, Electra and Opt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a941120b-8d49-46f6-b37b-f29f162a84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DistilBERT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13467' max='13467' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13467/13467 3:14:03, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>0.998553</td>\n",
       "      <td>0.998552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.999555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.999666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Training Phase\n",
    "bert_trainer, bert_model, bert_tokenizer = train_distilbert(train_texts, train_labels, test_texts, test_labels, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b547d01-084a-4a2e-b997-c8af1f04b2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec6e85-a9fd-4e16-a1cf-e6f3b1315c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GPT-2 model\n",
    "gpt2_trainer, gpt2_model, gpt2_tokenizer = train_gpt2(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efce18-3ded-4857-943b-26cac47f337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_trainer, llama_model, llama_tokenizer = train_llama(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f9334-afe0-4355-a25d-67eedbf94a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ELECTRA model\n",
    "electra_trainer, electra_model, electra_tokenizer = train_electra(train_texts, train_labels, test_texts, test_labels, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117f380-529a-4d49-b5be-accc6895c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train OPT model\n",
    "opt_trainer, opt_model, opt_tokenizer = train_opt(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec085c2d-f02d-49dc-8412-c12607882cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a2bd33-6cd6-43e8-9337-decd7bbc1796",
   "metadata": {},
   "source": [
    "# Model Evaluation Under Outside Data(Buzzfeed) - Of One Model (distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31ff9ae2-902a-466c-a946-a8da3e72013f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>hillary’s top donor country auctioned isi sex ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "177  hillary’s top donor country auctioned isi sex ...      0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BuzzFeed datasets\n",
    "buzzfeed_real_df = pd.read_csv('./data/BuzzFeed_real_news_content.csv')\n",
    "buzzfeed_fake_df = pd.read_csv('./data/BuzzFeed_fake_news_content.csv')\n",
    "\n",
    "# Add 'label' column: 1 for real news, 0 for fake news\n",
    "buzzfeed_real_df['label'] = 1\n",
    "buzzfeed_fake_df['label'] = 0\n",
    "\n",
    "# Retain only relevant columns ('title', 'text', 'label') and drop rows with missing text\n",
    "buzzfeed_real_df = buzzfeed_real_df[['text', 'label']].dropna(subset=['text'])\n",
    "buzzfeed_fake_df = buzzfeed_fake_df[['text', 'label']].dropna(subset=['text'])\n",
    "\n",
    "# Combine real and fake datasets into one\n",
    "buzzfeed_combined_df = pd.concat([buzzfeed_real_df, buzzfeed_fake_df], ignore_index=True)\n",
    "# Apply preprocessing to 'text' column\n",
    "buzzfeed_combined_df['text'] = buzzfeed_combined_df['text'].apply(preprocess_text)\n",
    "# Display the cleaned data\n",
    "buzzfeed_combined_df.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "54d90d33-9a13-47a7-a57e-9d3bf3f14cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eeacea9f-af1a-430d-bb46-eeed7568adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DistilBERT model from ./model/distilbert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Detection Phase\n",
    "# Load trained models and tokenizers\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e05fcca-041e-4ca5-9554-e1fd8a506350",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7017511b-3d15-4049-aad3-f3ff4bc14d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for evaluation\n",
    "texts = buzzfeed_combined_df['text'].tolist()\n",
    "labels = buzzfeed_combined_df['label'].tolist()\n",
    "\n",
    "# Store predictions and probabilities for evaluation\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# Run inference on each sample\n",
    "with torch.no_grad():\n",
    "    for text in texts:\n",
    "        # Tokenize and get model predictions\n",
    "        inputs = distilbert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "        outputs = distilbert_model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_label = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "        probabilities.append(probs.cpu().numpy()[0][1])  # Probability of class 1 (real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1feca1e-1a21-4a0a-ae74-913bdac7af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Log Loss: 5.6267\n",
      "Brier Score Loss: 0.4691\n",
      "Matthews Correlation Coefficient: 0.0539\n",
      "Cohen's Kappa Score: 0.0330\n",
      "ROC AUC Score: 0.4629\n",
      "Accuracy Score: 0.5165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:171: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax_.legend(loc=\"lower right\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Metrics and plots saved to: ./outputs/distilbert_only\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for compatibility with metrics functions\n",
    "y_true = np.array(labels)\n",
    "y_pred = np.array(predictions)\n",
    "y_prob = np.array(probabilities)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "metrics_log = {\n",
    "    \"Buzzfeed_Log Loss\": log_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Brier Score Loss\": brier_score_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "    \"Buzzfeed_Cohen's Kappa Score\": cohen_kappa_score(y_true, y_pred),\n",
    "    \"Buzzfeed_ROC AUC Score\": roc_auc_score(y_true, y_prob),\n",
    "    \"Buzzfeed_Accuracy Score\": accuracy_score(y_true, y_pred),\n",
    "}\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Print the metrics log\n",
    "print(\"Buzzfeed_Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Generate and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title(\"ROC Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_roc_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title(\"Precision-Recall Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_precision_recall_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Summarize metrics in a DataFrame for quick inspection if needed\n",
    "metrics_df = pd.DataFrame(metrics_log, index=[0])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_summary.csv\"), index=False)\n",
    "\n",
    "print(\"Evaluation complete. Metrics and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e652dc1-fea1-4463-af0f-11572f915c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd8db39-3965-4794-97f0-a779c6e7f88b",
   "metadata": {},
   "source": [
    "# Model Evaluation Distilbert - Under Random Generation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b0a7cdb-bebf-4245-a98f-e11e541580c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DistilBERT model from ./model/distilbert\n",
      "Prediction for custom data: 0 (Real News Probability: 0.00)\n",
      "News is Fake\n"
     ]
    }
   ],
   "source": [
    "# Detection function using DistilBERT\n",
    "def detect_with_distilbert(text, model, tokenizer, threshold=0.5):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    fake_prob = probs[0][0].item()\n",
    "    real_prob = probs[0][1].item()\n",
    "    prediction = 1 if real_prob >= threshold else 0\n",
    "    return prediction, real_prob  # returning probability for ROC and PR curves\n",
    "\n",
    "\n",
    "test_text=\"Cop Shares Racist Meme About Michelle Obama; Now That Cop Is Having A VERY Bad Day (IMAGES)After the election of Donald Trump many folks seem to see it as a permission slip to be as racist and vile as possible. However, here s the thing, you re still going to get called out as racist and vile. And one Alabama police officer just found this out the hard way.According to the Washington Post: Talladega Police Officer Joel Husk was terminated Wednesday for violating the department s social media and code of conduct policies, City Manager Patrick Bryant said. What did he do? So glad you asked: Husk had posted several memes on his Facebook page, including one showing Obama and Melania Trump.  Fluent in Slovenian, English, French, Serbian, and German,  it said over Trump s photo. Over Obama s, it read:  Fluent in Ghetto. Not only that, he posted several extraordinarily racist memes:via Washington Postvia Washington PostAccording to the City Manager, the statements were  deemed to be biased or racially insensitive or derogatory  and because of that, they  have to take action to correct it. If you re going to be a police officer and serve all the public, you can t assume black people standing up for their rights are equivalent to the KKK. That s about the most horrific equivalence imaginable.Also, according to WaPo: Husk, 37, who had been with the department for about two and a half years, had also shared a meme showing President Obama with the words:  Was Dallas a terrorist attack? Yes! Carried out by Obama s own homegrown terrorist group! Which is a blatant lie and anyone who were to feel that way belongs nowhere near law enforcement. The city took the proper action letting this racist cop go, and hopefully it will be an example to police departments all over the country that this sort of behavior simply cannot be tolerated.Trump s election must not be allowed to serve as a permission slip to bigots everywhere that it s fine to be as awful as possible, because here in the land of the free and the home of the brave, everyone is protected. Everyone, regardless of color, class, gender, sexual orientation, or creed.Featured Photo by Chip Somodevilla/Getty Images'\"\n",
    "\n",
    "# Initialize DistilBERT model and tokenizer\n",
    "device = torch.device(\"cpu\")\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Predict and print result for custom data\n",
    "result, real_prob = detect_with_distilbert(test_text, distilbert_model, distilbert_tokenizer)\n",
    "print(f\"Prediction for custom data: {result} (Real News Probability: {real_prob:.2f})\")\n",
    "\n",
    "if result == 0:\n",
    "    print(\"News is Fake\")\n",
    "else:\n",
    "    print(\"News is Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12bee1-1638-4fab-b922-74b5c21fc6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8debe46c-5ba7-43ce-8163-e3f44f858afe",
   "metadata": {},
   "source": [
    "# Model Evaluiation Under Simpilar Trained Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76ba2155-1e6d-484f-879a-c02565d59d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISOT_Fake_News_Dataset Evaluation Metrics:\n",
      "ISOT_Fake_News_Dataset_Log Loss: 0.0028\n",
      "ISOT_Fake_News_Dataset_Brier Score Loss: 0.0002\n",
      "ISOT_Fake_News_Dataset_Matthews Correlation Coefficient: 0.9996\n",
      "ISOT_Fake_News_Dataset_Cohen's Kappa Score: 0.9996\n",
      "ISOT_Fake_News_Dataset_ROC AUC Score: 0.9998\n",
      "ISOT_Fake_News_Dataset_Accuracy Score: 0.9998\n",
      "ISOT_Fake_News_Dataset_F1 Score: 0.9998\n",
      "Evaluation complete. Metrics, logs, and plots saved to: ./outputs/distilbert_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:171: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax_.legend(loc=\"lower right\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = test_labels\n",
    "y_pred = []\n",
    "y_score = []\n",
    "\n",
    "# Run detection on test data\n",
    "for text in test_texts:\n",
    "    pred_label, real_prob = detect_with_distilbert(text, distilbert_model, distilbert_tokenizer)\n",
    "    y_pred.append(pred_label)\n",
    "    y_score.append(real_prob)  # For ROC and Precision-Recall curves\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "log_loss_value = log_loss(y_true, y_score)\n",
    "brier_score = brier_score_loss(y_true, y_score)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "# Log and save metrics\n",
    "metrics_log = {\n",
    "    \"ISOT_Fake_News_Dataset_Log Loss\": log_loss_value,\n",
    "    \"ISOT_Fake_News_Dataset_Brier Score Loss\": brier_score,\n",
    "    \"ISOT_Fake_News_Dataset_Matthews Correlation Coefficient\": mcc,\n",
    "    \"ISOT_Fake_News_Dataset_Cohen's Kappa Score\": kappa,\n",
    "    \"ISOT_Fake_News_Dataset_ROC AUC Score\": roc_auc,\n",
    "    \"ISOT_Fake_News_Dataset_Accuracy Score\": accuracy,\n",
    "    \"ISOT_Fake_News_Dataset_F1 Score\": f1\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"ISOT_Fake_News_Dataset Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame(list(metrics_log.items()), columns=[\"Metric\", \"Score\"])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_summary.csv\"), index=False)\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_confusion_matrix_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title('ROC Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_roc_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title('Precision-Recall Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_precision_recall_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Evaluation complete. Metrics, logs, and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf4826-e872-4eb4-b81c-882d7a33020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0aa35a-4650-4bf2-9250-ede453d9ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load generation models\n",
    "gpt2_model, gpt2_tokenizer = load_gpt2()\n",
    "llama_model, llama_tokenizer = load_llama()\n",
    "opt_model, opt_tokenizer = load_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a03ed56e-f678-4c8b-9ba3-63218a4e13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models \n",
    "# models = {\n",
    "#     'distilbert_gpt2': (gpt2_model, gpt2_tokenizer, detect_with_distilbert_gpt2),\n",
    "#     'distilbert_llama': (llama_model, llama_tokenizer, detect_with_distilbert_llama),\n",
    "#     'distilbert_opt': (opt_model, opt_tokenizer, detect_with_distilbert_opt)\n",
    "# }\n",
    "\n",
    "# Dictionary to store models for detection\n",
    "models = {\n",
    "    'distilbert_gpt2': (gpt2_model, gpt2_tokenizer, detect_with_distilbert_gpt2),\n",
    "    'distilbert_electra': (electra_model, electra_tokenizer, detect_with_distilbert_electra),\n",
    "    'distilbert_opt': (opt_model, opt_tokenizer, detect_with_distilbert_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc79a8ff-a1a8-45e8-a5ae-87aafac4a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data and labels\n",
    "test_data = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "# Initialize results dictionary to store metrics for each combination\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69d7c4-2619-46f6-a021-0810ff71b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (gen_model, gen_tokenizer, detect_func) in models.items():\n",
    "    print(f\"Running detection for: {name}\")\n",
    "\n",
    "    y_true = test_data['label'].values\n",
    "    y_pred = []\n",
    "    y_score = []  # Store similarity scores for ROC and Precision-Recall curves\n",
    "\n",
    "    # Perform detection on test data\n",
    "    for text in test_data['text']:\n",
    "        result = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        pred_label = 1 if result == \"Real News Detected.\" else 0\n",
    "        y_pred.append(pred_label)\n",
    "\n",
    "        # Get similarity score from the detection function\n",
    "        # Modify detect_func to return score alongside label\n",
    "        _, similarity_score = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        y_score.append(similarity_score)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'], output_dict=True)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_true, y_pred, target_names=['Fake', 'Real'])}\")\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'confusion_matrix_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'roc_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n",
    "    plt.title(f'Precision-Recall Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'precision_recall_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "for name, metrics in results.items():\n",
    "    pd.DataFrame(metrics).to_csv(os.path.join(OUTPUT_DIR, name, f\"{name}_metrics.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

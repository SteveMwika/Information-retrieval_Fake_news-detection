{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a1a6b1-c47b-4af2-844a-5f23d76ac3cb",
   "metadata": {
    "id": "b4a1a6b1-c47b-4af2-844a-5f23d76ac3cb"
   },
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th><h1>CS 5364</h1><h2>Information Retrieval</h2>\n",
    "        <h1 style=\"color:maroon;\">Team Project Assignment</h1>\n",
    "        <h2 style=\"color:maroon;\">Second Submission</h2></th>\n",
    "        <th><img src=\"https://www.ttu.edu/traditions/images/raiderstatue.jpg\" width=225 height=116 /></th>\n",
    "        <th><p>Texas Tech University Matador Song</p>\n",
    "            <p>Fight, Matadors, for Tech!<br>\n",
    "                Songs of love we'll sing to thee,<br>\n",
    "                Bear our banners far and wide.<br>\n",
    "                Ever to be our pride,<br>\n",
    "                Fearless champions ever be.<br>\n",
    "                Stand on heights of victory.<br>\n",
    "                Strive for honor evermore.<br>\n",
    "                Long live the Matadors!</p>\n",
    "                <p>Music by Harry Lemaire, words by R.C. Marshall</p></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7f8fb-882d-4098-adea-e82a20733aa5",
   "metadata": {
    "id": "4fb7f8fb-882d-4098-adea-e82a20733aa5"
   },
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">C.L.A.I.M - \"Content Legitimacy Analysis and Information Management\"</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Shuainan (Eric) Liu</bf></h4></li>\n",
    "<li style=\"color:maroon\"><h4><bf>Steve Mwika</bf></h4></li>\n",
    "<li style=\"color:maroon\"><h4><bf>Mallikarjuna Reddy Bobbala</bf></h4></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507e5be-5fe6-415b-afa0-ed6e1f22f27c",
   "metadata": {
    "id": "f507e5be-5fe6-415b-afa0-ed6e1f22f27c"
   },
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">IR Problem</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>What is the problem on which the team worked for this submission?</bf></h4></li>\n",
    "    <ul>\n",
    "        <li>The problem we propose to address is Fake News Detection Based on Natural Language Processing (NLP) and Generative Pre-trained Transformer (GPT).</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Is it the same or a different problem than the problem(s) proposed in the proposal?  If changes in scope or other changes to the problem have been made since the proposal, please explain here.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li>The same problem as proposed in the proposal.</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Please summarize here what advances and lessons learned the team made in solving the problem for this submission.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Advances:</h5>\n",
    "            <ul>\n",
    "                <li>Advance...</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><h5>Lessons Learned:</h5>\n",
    "            <ul>\n",
    "                <li>Lesson Learned...</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939f91c-d08c-43f1-8290-9f6e0507e92a",
   "metadata": {
    "id": "1939f91c-d08c-43f1-8290-9f6e0507e92a"
   },
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">What other ideas, models, approaches, and/or helpful suggestions have you found since the last team submission related to solving the IR problem or similar problems by others?</h1>\n",
    "\n",
    "<hr>\n",
    "<ul>\n",
    "    <li style=\"color:maroon\"><h4><bf>N. Seddari, A. Derhab, M. Belaoued, W. Halboob, J. Al-Muhtadi and A. Bouras, \"A Hybrid Linguistic and Knowledge-Based Analysis Approach for Fake News Detection on Social Media,\" in IEEE Access, vol. 10, pp. 62097-62109, 2022, doi: 10.1109/ACCESS.2022.3181184.\n",
    "keywords: {Fake news;Feature extraction;Linguistics;Knowledge based systems;Syntactics;Social networking (online);Semantics;Social media;fake news detection;linguistic analysis;knowledge analysis;fact-checking website}.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>  This paper focuses on the challenge of detecting the fake news and mis information accurately, specifically focusing on improving the detection performance by taking advantage of the NLP models </li>\n",
    "        <li><h5>Past Solution Ideas:</h5>  The approaches available emphasized include machine learning classifiers and standalone deep learning models like the RNN and the CNNs and the basic trasnformer architectures that hae faced limitations in capturing the complex language nuances in the mis information</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>  The author in this paper proposes a hybrid model which combines the transformers like BERT with the other available deep learning architectures which can enhances the context comprehension and detect disinformation with the more accuracy</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>  This paper have given future insights into integrating the multimodel data with the NLP approaches which enhances the model explainability which can improve the robustness of the fake news detection system</li>\n",
    "        <li><h5>Evaluation Ideas:</h5>  The authors recommended the rigorous benchmarking of using the large balenced datasets and the testing on the real world misinformaion sources to assess models robustness across diverse news types and platforms</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>  For this project, the paper's hybrid model approach combining BERT for contextual understanding and transformer-based models could be instrumental.</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"color:maroon\"><h4><bf>M. Heidari et al., \"BERT Model for Fake News Detection Based on Social Bot Activities in the COVID-19 Pandemic,\" 2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON), New York, NY, USA, 2021, pp. 0103-0109, doi: 10.1109/UEMCON53757.2021.9666618. keywords: {COVID-19;Pandemics;Social networking (online);Bit error rate;Transfer learning;Transformers;Mobile communication;Fake news;Bot detection;Natural language processing;Neural Network;Social media},\n",
    "\n",
    "</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>  This paper focus on the challenge of the fake news detection on social media specifically focusing on the fake news spreading during the COVID-19 pandemic by distinguishing content spread by human accounts versus social bots </li>\n",
    "        <li><h5>Past Solution Ideas:</h5>  Past solutions focused on various machine learning and NLP techniques which includes topic modelling which categorize misinformation which lacked approaches that combined bot detection with fake news identification\n",
    "</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>  The authors in this paper propose using a BERT based model for the fake news detection which incorporating features from bot detection which can determine whether the post coming from the bot or a human\n",
    "</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>  Future directions shows that improving detection by adding more features such as fake claim score and integrating multimodal data to enhance the detection models robustness and accuracy</li>\n",
    "        <li><h5>Evaluation Ideas:</h5>  The authors suggest evaluating the models effectiveness by comparing accuracy and F-1 scors across feature sets, focusing on those with and without bot related features so determine which elements improve the detection reliabilitys</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5> Levaraging the BERT for contextual analysis can be instrumental in the project.</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Y. Guo, H. Lamaazi and R. Mizouni, \"Smart Edge-based Fake News Detection using Pre-trained BERT Model,\" 2022 18th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob), Thessaloniki, Greece, 2022, pp. 437-442, doi: 10.1109/WiMob55322.2022.9941689. keywords: {Wireless communication;Crowdsensing;Image edge detection;Computational modeling;Bit error rate;Computer architecture;Fake news;Fake News;BERT;Text Classification;Deep Learning;Fine-Tuning;Edge Computing;Distributed Architecture},</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>The Fake news on social media is increasingly prevalent, which requires the efficient detection. The centralized fake news detection methods are mostly limited by the very high processing requirements and geographical differences in news correctness, which is affecting their scalability and reliability.  </li>\n",
    "        <li><h5>Past Solution Ideas:</h5> The available traditional approaches for the fake news detection includes the centralized architectures which utilizes the various NLP models like CNN-GRU and word embedding techniques (e.g., Word2Vec, GloVe). These are the methods achieved varying levels of accuracy but faced challenges in scalability and region-specific reliability. </li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5> The authors in this paper proposes a region-based, distributed architecture using a mobile crowdsensing environment where the edge servers handle local news detection. ThereBy deploying a pre-trained BERT model at edge nodes, they achieved the higher accuracy (91%) and reduced computational load. </li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>The paper gives insights into expanding to more domains and regions, and further optimizing the distributed mobile crowdsensing architecture for improved scalability and accuracy.  </li>\n",
    "        <li><h5>Evaluation Ideas:</h5>The Evaluation involves standard metrics like precision, recall, and F1-score, with 10-40 epochs to optimize accuracy. A balanced dataset was used to ensure reliable classification between true and fake news.  </li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>Utilizing a region-based model, like in the paper, could allow project to better address regional variations in news.  </li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>F. Al-Quayed, D. Javed, N. Z. Jhanjhi, M. Humayun and T. S. Alnusairi, \"Optimizing Fake News Detection: A Hybrid Transformer-Based Model for Enhanced Performance,\" in IEEE Access, doi: 10.1109/ACCESS.2024.3476432.keywords: {Fake news;Accuracy;Bidirectional control;Encoding;Deep learning;Long short term memory;Linguistics;Analytical models;Support vector machines;Social networking (online);Bi-Directional Deep Learning;Transformers;Fake news Detection},</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5>The paper addresses the growing problem of fake news, which spreads false information and affects public opinion and societal trust. Regular fact-checking methods are very slow to handle the large amount of content generated on social media, and existing machine learning models often lack the accuracy and adaptability needed to detect various patterns of disinformation.  </li>\n",
    "        <li><h5>Past Solution Ideas:</h5> Previous solutions have focused much on machine learning models such as CNNs, LSTMs, and basic BERT configurations to detect the fake news. These models focused on analyzing individual articles or headlines but could find difficulty with limitations in getting the context and sequence, often due to issues like vanishing gradients in deep learning architectures. </li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5> The authors in this paper proposes a hybrid model that integrates BERT with bidirectional deep learning layers (Bi-LSTM and Bi-GRU) to enhance fake news detection. This approach takes advantage of BERT’s contextual embeddings and the sequential pattern recognition of bi-directional models, which results in improved accuracy and F1 scores. The model uses the WELFake dataset, which includes diverse labeled examples, allowing for robust performance in distinguishing real from fake news. </li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5> The authors in this paper suggested that the future directions include refining the model by combining graph based techniques for better capturing of the relational data across the sources. They have also proposed expanding the model to address the multi-lingual fake news detection and social media specific language patterns to increase the versatality and also the accuracy across the various platforms </li>\n",
    "        <li><h5>Evaluation Ideas:</h5>The BERT+Bi-LSTM model showed an accuracy of 98.1% when tested using the WELFake dataset including measures like accuracy, precision, recall, and F1 score. Contextual embeddings and bidirectional layer processing together gave this model better performance when compared to other deep learning-based models and classical models.  </li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>The study places a strong emphasis on robust preprocessing.Using these preprocessing techniques could increase detection accuracy and model learning by fine-tuning the dataset.  </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e750733-0c99-440a-9abc-9fa8da8d722d",
   "metadata": {
    "id": "0e750733-0c99-440a-9abc-9fa8da8d722d"
   },
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">From Other Informal Resources</h2>\n",
    "<hr>\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>:https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5>******************************Used from source Word For word:**************************************\n",
    "\n",
    "test_text=\"Cop Shares Racist Meme About Michelle Obama; Now That Cop Is Having A VERY Bad Day (IMAGES)After the election of Donald Trump many folks seem to see it as a permission slip to be as racist and vile as possible. However, here s the thing, you re still going to get called out as racist and vile. And one Alabama police officer just found this out the hard way.According to the Washington Post: Talladega Police Officer Joel Husk was terminated Wednesday for violating the department s social media and code of conduct policies, City Manager Patrick Bryant said. What did he do? So glad you asked: Husk had posted several memes on his Facebook page, including one showing Obama and Melania Trump.  Fluent in Slovenian, English, French, Serbian, and German,  it said over Trump s photo. Over Obama s, it read:  Fluent in Ghetto. Not only that, he posted several extraordinarily racist memes:via Washington Postvia Washington PostAccording to the City Manager, the statements were  deemed to be biased or racially insensitive or derogatory  and because of that, they  have to take action to correct it. If you re going to be a police officer and serve all the public, you can t assume black people standing up for their rights are equivalent to the KKK. That s about the most horrific equivalence imaginable.Also, according to WaPo: Husk, 37, who had been with the department for about two and a half years, had also shared a meme showing President Obama with the words:  Was Dallas a terrorist attack? Yes! Carried out by Obama s own homegrown terrorist group! Which is a blatant lie and anyone who were to feel that way belongs nowhere near law enforcement. The city took the proper action letting this racist cop go, and hopefully it will be an example to police departments all over the country that this sort of behavior simply cannot be tolerated.Trump s election must not be allowed to serve as a permission slip to bigots everywhere that it s fine to be as awful as possible, because here in the land of the free and the home of the brave, everyone is protected. Everyone, regardless of color, class, gender, sexual orientation, or creed.Featured Photo by Chip Somodevilla/Getty Images'\"  </li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5> fake_data[\"label\"]=\"fake\"\n",
    "real_data[\"label\"]=\"real\"\n",
    "\n",
    "final_data= pd.concat([fake_data,real_data])\n",
    "\n",
    "final_data = final_data.sample(frac=1).reset_index(drop=True) </li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>https://github.com/Navy10021/FakeLense</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5> ****Some Data Preprocessing code: **** </li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5> def text_preprocessing(text):\n",
    "    # Check if the input is a string; if not, convert it to an empty string\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "        \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation + \"–—−±×÷\"), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)    \n",
    "    text = re.sub(r'reuters', '', text)\n",
    "    text = re.sub(r' +', ' ', text).strip()\n",
    "    return text </li>\n",
    "    </ul>\n",
    "    ...\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa84f4-a1dd-4df8-8fb2-25088b18e92e",
   "metadata": {
    "id": "0daa84f4-a1dd-4df8-8fb2-25088b18e92e"
   },
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Past Plans and Actual Tasks for the Second Submission, and Past/Current Plans for the Third Submission</h1>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Each team member plans to apply an IR solution to the problem and has the following accomplishments and plans:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: maroon\"><bf>Team Member Name</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Planned/Actual Team Member Tasks for Second Submission</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Past/Current Planned Team Member Tasks for Third Submission</bf></th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Shuainan Liu</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Search for research papers related to our project, 10/11/2024</li>\n",
    "                <li>Determine the model and dataset for project, 10/12/2024</li>\n",
    "                <li>Assist teammates with model construction and data preprocessing, 10/16/2024</li>\n",
    "                <li>Complete the second assignment report, 10/18/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks actually done for the second submission</bf></li>\n",
    "            <ul>\n",
    "                 <li>Search for research papers related to our project, 10/14/2024</li>\n",
    "                <li>Determine the model and dataset for project, 10/18/2024</li>\n",
    "                <li>Assist teammates with model construction and data preprocessing, 10/22/2024</li>\n",
    "                <li>Complete the second assignment report, 11/05/2024</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li<bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Complete the code for the fake news detection model, 10/24/2024</li>\n",
    "                <li>Create a flowchart and summarize the features of the project, 10/28/2024</li>\n",
    "                <li>Complete the third assignment report, 11/11/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Update on third submission tasks planned as of the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Complete the code for the fake news detection model, 11/08/2024</li>\n",
    "                <li>Create a flowchart and summarize the features of the project, 11/12/2024</li>\n",
    "                <li>Complete the third assignment report, 11/25/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Steve Mwika</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Search for research papers related to our project, 10/11/2024</li>\n",
    "                <li>Complete the code for the construction of the models, 10/15/2024</li>\n",
    "                <li>Assist teammates with report for the second assignment, 10/18/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks actually done for the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Search for research papers related to our project, 10/14/2024</li>\n",
    "                <li>Complete the code for the construction of the models, 10/28/2024</li>\n",
    "                <li>Assist teammates with report for the second assignment, 11/05/2024</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li<bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "               <li>Complete the training of NLP model, e.g., BERT-based model, 10/24/2024</li>\n",
    "                <li>Complete the testing phase and get the results, 10/28/2024</li>\n",
    "                <li>Assist teammates with report for the third assignment, 11/11/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Update on third submission tasks planned as of the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Complete the training of NLP model, e.g., BERT-based model, 11/10/2024</li>\n",
    "                <li>Complete the testing phase and get the results, 11/15/2024</li>\n",
    "                <li>Assist teammates with report for the third assignment, 11/25/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "      <tr style=\"text-align:left\">\n",
    "        <th>Mallikarjuna Reddy Bobbala</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Search for research papers related to our project, 10/11/2024</li>\n",
    "                <li>Complete the code for data preprocessing, 10/15/2024</li>\n",
    "                <li>Complete data preprocessing, 10/16/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks actually done for the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Search for research papers related to our project, 10/14/2024</li>\n",
    "                <li>Complete the code for data preprocessing, 10/23/2024</li>\n",
    "                <li>Complete data preprocessing, 10/25/2024</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li<bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                   <li>Search for research papers related to our project, 10/11/2024</li>\n",
    "                <li>Complete the code for data preprocessing, 10/15/2024</li>\n",
    "                <li>Complete data preprocessing, 10/16/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Update on third submission tasks planned as of the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Complete the training of GPT model, 11/10/2024</li>\n",
    "                <li>Complete the evaluation of experimental results, 11/18/2024</li>\n",
    "                <li>Assist teammates with report for the third assignment, 11/25/2024</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f71f4-6357-4057-8c39-5d8a6d7b800c",
   "metadata": {
    "id": "c36f71f4-6357-4057-8c39-5d8a6d7b800c"
   },
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Current Solution Status</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa796-2ef5-46fd-bdf7-1d7774298edb",
   "metadata": {
    "id": "1fffa796-2ef5-46fd-bdf7-1d7774298edb"
   },
   "source": [
    "<h2 style=\"color:teal\">What computer hardware, programming language, main software packages, and data files are recommended to be used to run the software for this submission?</h2>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <h5 style=\"color:maroon\">Computer Hardware</h5>\n",
    "            <ul>\n",
    "                <li>Processor: AMD Ryzen 5 5600 6-Core Processor, 3501 Mhz, 6 Core(s), 12 Logical Processor(s)</li>\n",
    "                <li>RAM: 32GB</li>\n",
    "                <li>System type: 64-bit operating system, x64-based processor</li>\n",
    "                <li>GPU: RTX 3060 Ti</li>\n",
    "                <li>SSD: 500 GB, External Drive: 1 TB</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><h5 style=\"color:maroon\">Programming Language</h5>Python 3.12.7</li>\n",
    "        <li><h5 style=\"color:maroon\">Main Software Packages</h5>os, torch, pandas, numpy, wordcloud, transformers, sklearn, datasets, matplotlib.pyplot, seaborn, PIL, re, string, nltk, datetime, time, Cuda 11.8</li>\n",
    "        <li><h5 style=\"color:maroon\">Data</h5>ISOT Fake News Dataset, BuzzFeed News Analysis and Classification </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4681706-eda0-4131-9418-1c803a494611",
   "metadata": {
    "id": "a4681706-eda0-4131-9418-1c803a494611"
   },
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">What are the performance results of the team's solutions in comparison with performance results from journal/conference papers and other informal resources?</h2>\n",
    "\n",
    "<p>For the second submission, each team member should give at least one reference to compare against the performance of the solution on which the team member worked.  Performance includes but is not limited to the amount of memory consumed, the order of the algorithms used, computation time, number of operations performed, experimental results on various data sets or trials, and measurements, such as precision, recall, accuracy, F-measure, and cluster purity/silouette.  Graphs, such as the ROC curve, precision/recall curve, scatter plots showing the relationship between two attributes, line charts showing model performance at various training points, and bar charts comparing approaches, may also be used.</p>\n",
    "\n",
    "<p>If a direct comparison is not available, try to find a reference that is similar in nature.  In addition, discuss with the course instructors any difficulty you are having in finding references to compare against.  Other ideas include implementing more solutions to compare against each other.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Team Solution - DistilBERT for Fake News Detection</h3>\n",
    "\n",
    "<p>Our solution uses the DistilBERT model, fine-tuned on the ISOT Fake News Dataset. The model achieves high accuracy and generalization capabilities, which are illustrated by the ROC AUC score of 0.98 and F1 score of 0.93, as shown in the confusion matrix and ROC/PR curves. The training and validation accuracy/loss curves demonstrate stable convergence, indicating robust performance without overfitting.</p>\n",
    "\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkblue\">Informal Reference: <a href=\"https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook\" target=\"_blank\">BERT-based Fake News Detector on Kaggle</a> </h4> \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><b>Comparison with Reference Solution</b></th>\n",
    "        <th style=\"color: darkgreen\"><b>Reasons why the performance of the team's solution is better/same/worse</b></th>\n",
    "    </tr>\n",
    "    <!-- Confusion Matrix Comparison -->\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><b>Confusion Matrix Comparison</b></p>\n",
    "            <p>Our team’s confusion matrix shows significantly fewer misclassifications compared to the reference solution. The team model demonstrates a near-perfect accuracy with minimal false positives and false negatives, underscoring its reliability in differentiating between fake and real news.</p>\n",
    "            <div style=\"display: flex; align-items: center;\">\n",
    "                <img src=\"./Images evaluation/2.PNG\" alt=\"Confusion Matrix (Reference)\" style=\"width: 250px; height: auto; margin-right: 10px;\">\n",
    "                <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_confusion_matrix_distilbert.png\" alt=\"Confusion Matrix (Team)\" style=\"width: 250px; height: auto;\">\n",
    "            </div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>The higher accuracy in our model’s confusion matrix results from the ability of DistilBERT to capture nuanced text patterns, which is essential for accurate fake news classification. Our approach also involved careful data preprocessing and fine-tuning specific to the ISOT dataset, allowing for a better alignment with the dataset's characteristics.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <!-- Classification Report Comparison -->\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><b>Classification Report</b></p>\n",
    "            <p>The classification report of the team’s model demonstrates an improvement in precision, recall, and F1 score over the reference solution. Our DistilBERT model achieves an F1 score of 0.99, indicating balanced precision and recall and effective handling of both classes (fake and real news) in the dataset.</p>\n",
    "            <div style=\"display: flex; align-items: center;\">\n",
    "                <img src=\"./Images evaluation/3.PNG\" alt=\"Classification Report (Reference)\" style=\"width: 250px; height: auto; margin-right: 10px;\">\n",
    "                <img src=\"./Images evaluation/Training Data.PNG\" alt=\"Classification Report (Team)\" style=\"width: 250px; height: auto;\">\n",
    "            </div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>The higher F1 score highlights the team's solution's robustness in detecting fake news accurately without sacrificing recall. This improvement can be attributed to the specific fine-tuning of the model on the ISOT dataset, which helped it to adapt better to the distribution of fake and real news examples.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <!-- ROC Curve Comparison -->\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><b>ROC Curve Comparison</b></p>\n",
    "            <p>The ROC curve for our team solution achieves an almost perfect AUC score of 0.9998, showcasing the model’s ability to distinguish between real and fake news with high precision. This is a noticeable improvement over the reference model's ROC curve.</p>\n",
    "            <div style=\"display: flex; align-items: center;\">\n",
    "                <img src=\"./Images evaluation/4.PNG\" alt=\"ROC Curve (Reference)\" style=\"width: 250px; height: auto; margin-right: 10px;\">\n",
    "                <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_roc_curve_distilbert.png\" alt=\"ROC Curve (Team)\" style=\"width: 250px; height: auto;\">\n",
    "            </div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>The high AUC score underscores the effectiveness of DistilBERT in capturing semantic differences between real and fake news. This is further enhanced by careful preprocessing and balanced training on the ISOT dataset, which enabled the model to achieve superior classification boundaries.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <!-- Precision-Recall Curve Comparison -->\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p><b>Precision-Recall Curve Comparison</b></p>\n",
    "            <p>The team solution's precision-recall curve indicates higher precision across all levels of recall, maintaining stability without significant drop-offs. This is particularly beneficial for fake news detection, where maintaining high precision is critical to avoid false alarms.</p>\n",
    "            <div style=\"display: flex; align-items: center;\">\n",
    "                <img src=\"./Images evaluation/5.PNG\" alt=\"Precision-Recall Curve (Reference)\" style=\"width: 250px; height: auto; margin-right: 10px;\">\n",
    "                <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_precision_recall_curve_distilbert.png\" alt=\"Precision-Recall Curve (Team)\" style=\"width: 250px; height: auto;\">\n",
    "            </div>\n",
    "        </td>\n",
    "        <td>\n",
    "            <p>The stability of the precision-recall curve reflects the effectiveness of the team's model in handling class imbalances. The fine-tuning on a specifically curated fake news dataset allowed our model to retain high precision even at higher recall thresholds, showcasing its applicability for real-world fake news detection.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Team Solution - DistilBERT for Fake News Detection on Buzzfeed Dataset</h3> <p>The team used the DistilBERT model, initially fine-tuned on the ISOT Fake News Dataset, to evaluate its performance on the Buzzfeed dataset as an external data source. This approach allowed the team to observe how well the model generalizes to new, unseen data with varied sources and styles without additional fine-tuning. The Buzzfeed dataset presented a unique challenge due to its diversity, and testing on this data demonstrates the model's robustness and its limitations when applied to different real-world datasets beyond its training set.</p>\n",
    "\n",
    "<p>Fill in description of team solution</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\">Paper/Informal Reference: Internal Team Reference</h4>\n",
    "<table>\n",
    "   <tr>\n",
    "      <th style=\"color: darkgreen\"><b>Comparison with Reference Solution</b></th>\n",
    "      <th style=\"color: darkgreen\"><b>Reasons why the performance of the team's solution is better/same/worse</b></th>\n",
    "   </tr>\n",
    "   <!-- Confusion Matrix Comparison --> \n",
    "   <tr>\n",
    "      <td>\n",
    "         <p><b>Confusion Matrix Comparison</b></p>\n",
    "         <p>The confusion matrix for the team’s Buzzfeed dataset model reveals a distinct difference in performance compared to the ISOT dataset. The Buzzfeed model shows some degree of misclassification in both classes, likely due to the more diverse and complex nature of the data in this dataset.</p>\n",
    "         <div style=\"display: flex; align-items: center;\"> <img src=\"./Images evaluation/confusion_matrix.png\" alt=\"Confusion Matrix (Buzzfeed)\" style=\"width: 250px; height: auto; margin-right: 10px;\"> <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_confusion_matrix_distilbert.png\" alt=\"Confusion Matrix (ISOT)\" style=\"width: 250px; height: auto;\"> </div>\n",
    "      </td>\n",
    "      <td>\n",
    "         <p>The higher misclassification rate in the Buzzfeed dataset is likely due to its variety in article sources and styles, which poses a greater challenge for the model. This emphasizes the importance of dataset-specific fine-tuning, as the ISOT dataset allowed for more straightforward classification due to its homogeneous structure.</p>\n",
    "      </td>\n",
    "   </tr>\n",
    "   <!-- ROC Curve Comparison --> \n",
    "   <tr>\n",
    "      <td>\n",
    "         <p><b>ROC Curve Comparison</b></p>\n",
    "         <p>The ROC curve for the Buzzfeed dataset model shows a lower AUC than the ISOT model, indicating that the model faced challenges in achieving high true positive rates across varying decision thresholds.</p>\n",
    "         <div style=\"display: flex; align-items: center;\"> <img src=\"./Images evaluation/roc_curve.png\" alt=\"ROC Curve (Buzzfeed)\" style=\"width: 250px; height: auto; margin-right: 10px;\"> <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_roc_curve_distilbert.png\" alt=\"ROC Curve (ISOT)\" style=\"width: 250px; height: auto;\"> </div>\n",
    "      </td>\n",
    "      <td>\n",
    "         <p>The lower AUC on the Buzzfeed dataset reflects the added complexity and varied nature of the data. The results indicate that additional fine-tuning or pre-processing steps may be necessary to adapt DistilBERT more effectively for datasets with diverse content and structure.</p>\n",
    "      </td>\n",
    "   </tr>\n",
    "   <!-- Precision-Recall Curve Comparison --> \n",
    "   <tr>\n",
    "      <td>\n",
    "         <p><b>Precision-Recall Curve Comparison</b></p>\n",
    "         <p>The precision-recall curve for the Buzzfeed dataset shows a lower precision at various recall levels compared to the ISOT model. This result highlights the difficulty in maintaining high precision when recall is high in a dataset with diverse news sources.</p>\n",
    "         <div style=\"display: flex; align-items: center;\"> <img src=\"./Images evaluation/precision_recall_curve.png\" alt=\"Precision-Recall Curve (Buzzfeed)\" style=\"width: 250px; height: auto; margin-right: 10px;\"> <img src=\"./Images evaluation/ISOT_Fake_News_Dataset_precision_recall_curve_distilbert.png\" alt=\"Precision-Recall Curve (ISOT)\" style=\"width: 250px; height: auto;\"> </div>\n",
    "      </td>\n",
    "      <td>\n",
    "         <p>The Buzzfeed dataset's lower precision-recall values underscore the importance of dataset-specific calibration. The broader range of topics and writing styles in Buzzfeed articles requires additional adjustments in model training to optimize performance across recall levels.</p>\n",
    "      </td>\n",
    "   </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Discussion/Summary of Solution Results</h3>\n",
    "\n",
    "<p>In summary, the team’s solution demonstrates the power of DistilBERT as a model for fake news detection, achieving high performance on the ISOT Fake News Dataset. The model's F1 score of 0.99 and near-perfect ROC AUC score indicate robust accuracy and an excellent balance of precision and recall. Our approach of careful preprocessing and fine-tuning specific to the ISOT dataset allowed the model to capture nuanced text patterns associated with fake and real news. This solution significantly outperforms a BERT-based fake news detector from Kaggle, particularly in terms of accuracy and F1 score, highlighting the strength of our training methodology and model configuration.</p>\n",
    "\n",
    "<p>When tested on an external dataset, the Buzzfeed dataset, without additional fine-tuning, the model faced more challenges, as seen in the lower AUC and precision-recall scores. The diversity and complexity of the Buzzfeed dataset, with its varied article sources and writing styles, posed additional hurdles that the model was less prepared to handle due to the lack of dataset-specific fine-tuning. The higher misclassification rate and lower AUC compared to the ISOT dataset illustrate the limitations of a one-size-fits-all model in the context of diverse real-world data. These results underscore the importance of adapting models to the specific characteristics of each dataset through targeted fine-tuning or calibration steps.</p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e79bd9-e8dc-4769-b9ab-d709b16918a6",
   "metadata": {
    "id": "47e79bd9-e8dc-4769-b9ab-d709b16918a6"
   },
   "source": [
    "\n",
    "<h1 style=\"color: darkgoldenrod\">Software</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beed320-23a0-4664-9483-b0e626619d81",
   "metadata": {
    "id": "9beed320-23a0-4664-9483-b0e626619d81"
   },
   "source": [
    "<p>Please be sure to submit a requirements.txt file so that the instructors can easily run the code in this Jupyter Notebook.  The requirements.txt file should be in the same working directory as the Jupyter Notebook.  Also, please give any special instructions beyond the normal running of code in a Jupyter Notebook, such as where data files should be placed if not in the working directory of this Jupyter Notebook or if some of the installed software packages have additional requirements beyond \"pip install\".</p>\n",
    "\n",
    "<p>Each code cell should have contextually related code, such as a class, function implementing a major algorithm, or a set of short functions that support a larger function in a subsequent cell.  Code cells should also be present to show the performance/evaluation of a solution through well labeled graphs, tables, and/or performance measure values.</p>\n",
    "\n",
    "<p>The code cells also can be organized by each team member's solution.</p>\n",
    "\n",
    "<p>Each major set of related code cells should have the purpose of the code cells, the paper/informal references used (if any) to develop the code in the code cells, the team members who worked on the code cells, and major changes made to the code in the code cells by team members for this submission.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2 style=\"color: teal\">Are there any special instructions for running the code in this Jupyter Notebook for this submission?</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>If Attempting to train models on Gpu Cuda: \n",
    "        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118.</li>\n",
    "    <li>Make sure the Cuda Path in added to System environment</li>\n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6faba-e744-4216-a5a7-55834d8773b0",
   "metadata": {
    "id": "88e6faba-e744-4216-a5a7-55834d8773b0"
   },
   "outputs": [],
   "source": [
    "#to capture all of the installed packages so far (run by the team to submit with the Jupyter notebook)\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b9ece-5297-4cb8-a663-7587f16459d5",
   "metadata": {
    "id": "6e9b9ece-5297-4cb8-a663-7587f16459d5"
   },
   "outputs": [],
   "source": [
    "#to install all of the packages in requirements.txt (run by the instructors when grading the notebook)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d298cad8-bed1-4d45-aeb2-e6ce5df3a0d9",
   "metadata": {
    "id": "d298cad8-bed1-4d45-aeb2-e6ce5df3a0d9"
   },
   "outputs": [],
   "source": [
    "#packages to import to run the code in the Jupyter Notebook\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime  \n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8478dc-1750-41a0-b02c-a7e51f274122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "DISTILBERT_PATH = './model/distilbert'\n",
    "LLAMA_PATH = './model/llama'\n",
    "OPT_PATH = './model/opt'\n",
    "GPT2_PATH = './model/gpt2'\n",
    "ELECTRA_PATH = './model/electra'\n",
    "\n",
    "# Create model directories if they don't exist\n",
    "os.makedirs(DISTILBERT_PATH, exist_ok=True)\n",
    "os.makedirs(ELECTRA_PATH, exist_ok=True)\n",
    "os.makedirs(LLAMA_PATH, exist_ok=True)\n",
    "os.makedirs(OPT_PATH, exist_ok=True)\n",
    "os.makedirs(GPT2_PATH, exist_ok=True)\n",
    "\n",
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "\n",
    "# Define directories for saving outputs\n",
    "OUTPUT_DIR = './outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "COMBINATIONS = ['distilbert_gpt2', 'distilbert_llama', 'distilbert_opt']\n",
    "for combination in COMBINATIONS:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, combination), exist_ok=True)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edbbc2-6595-4dbe-a257-f9e35275a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. GPU or CPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b99d9c-7723-4585-abbf-d649f6351241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model_dir(base_path):\n",
    "    model_dirs = glob.glob(os.path.join(base_path, \"*\"))\n",
    "    if not model_dirs:\n",
    "        return None\n",
    "    latest_dir = max(model_dirs, key=os.path.getmtime)\n",
    "    return latest_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565039db-a366-44bf-adf9-f5928380d74a",
   "metadata": {
    "id": "565039db-a366-44bf-adf9-f5928380d74a"
   },
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Data Preprocessing for Fake News Detection</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is responsible for preprocessing text data for fake news detection. It loads fake and real news data, assigns labels, combines relevant fields into a single text column, and applies natural language processing techniques, such as tokenization, stopword removal, and lemmatization, to prepare the data for model training.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/preprocessing.py</li>\n",
    "    <li>https://www.kaggle.com/code/rein0706/fake-news-detection-using-cnn</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Mallikarjuna Reddy Bobbala</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/20/2024 - Preprocessing Completed</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b45c6-a6d2-4dcf-9941-6e15bb2697b9",
   "metadata": {
    "id": "db7b45c6-a6d2-4dcf-9941-6e15bb2697b9"
   },
   "outputs": [],
   "source": [
    "# code cells for running and evaluating the solution\n",
    "Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load data\n",
    "fake_data = pd.read_csv(\"./data/Fake.csv\")\n",
    "real_data = pd.read_csv(\"./data/True.csv\")\n",
    "\n",
    "# Data preprocessing and labeling\n",
    "fake_data[\"label\"] = \"fake\"\n",
    "real_data[\"label\"] = \"real\"\n",
    "final_data = pd.concat([fake_data, real_data])\n",
    "final_data = final_data.sample(frac=1).reset_index(drop=True)\n",
    "final_data['label'] = final_data['label'].map({'real': 1, 'fake': 0})\n",
    "\n",
    "# Combine title and text fields into a single text column for processing\n",
    "final_data['text'] = final_data['title'] + \" \" + final_data['text']\n",
    "final_data = final_data[['text', 'label']]\n",
    "\n",
    "# NLTK preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove content in brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "final_data[\"text\"] = final_data[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133f884-f8f9-47dd-9b93-1f92d3b02ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19aa7f-e111-4439-977f-99585ccf162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e8c8d-721c-4bac-aaf1-2d2853def200",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7c964-f004-446c-afab-3ea8035480a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1386d-10e6-446b-b3e7-522d41571d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.text[3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44024dbf-a49d-4901-8d34-cab79c43429c",
   "metadata": {
    "id": "44024dbf-a49d-4901-8d34-cab79c43429c"
   },
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - DistilBERT Model Training and Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is dedicated to training and evaluating a DistilBERT-based model for binary text classification, specifically targeting fake news detection. The main steps include initializing a pre-trained DistilBERT model and tokenizer, encoding and organizing the training and testing datasets, and configuring the training process with hyperparameters suited for efficient learning on CPU. This model is fine-tuned on labeled fake and real news data to classify news articles accurately.\n",
    "\n",
    "During training, metrics such as accuracy, precision, recall, and F1 score are computed at each epoch to monitor performance and adjust learning as needed. Additionally, the code saves the trained model and tokenizer at the specified output directory, enabling the model to be reused without retraining. The trained model can then be loaded using the provided `load_distilbert()` function for further inference or evaluation on new datasets. This block facilitates creating a robust and reusable fake news detector leveraging transformer-based language model capabilities.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve k Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/22/2024 - Completed Distilbert model Training code</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3f9cba-98c2-4c51-9a4f-488c07be834e",
   "metadata": {
    "id": "2b3f9cba-98c2-4c51-9a4f-488c07be834e"
   },
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "# 3. Train DistilBERT-based model\n",
    "def train_distilbert(train_texts, train_labels, test_texts, test_labels, epochs, output_dir='./model/distilbert'):\n",
    "    print(\"Training DistilBERT\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)\n",
    "\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels)\n",
    "    })\n",
    "\n",
    "    test_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels)\n",
    "    })\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,  # Smaller batch size for CPU\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,  # Higher accumulation for larger effective batch size\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,  # Slightly higher learning rate to reduce epochs\n",
    "        logging_dir='./distilbert_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        no_cuda=True,  # Ensure CPU-only\n",
    "        bf16=False,  \n",
    "        dataloader_num_workers=4  # Use multiple workers for data loading\n",
    "    )\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    return trainer, model, tokenizer\n",
    "\n",
    "# Load DistilBERT model\n",
    "def load_distilbert():\n",
    "    print(f\"Loading DistilBERT model from {DISTILBERT_PATH}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(DISTILBERT_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(DISTILBERT_PATH)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705fbc3-567d-44e5-8be5-6416b75129fd",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - GPT-2 Model Training and Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to fine-tune and evaluate a pre-trained GPT-2 model for causal language modeling. The main steps involve initializing the GPT-2 tokenizer and model, configuring the data for training and evaluation, and setting training parameters suitable for efficient processing on a CPU. The training process adjusts the model weights to fit the context of the provided dataset, making it capable of generating relevant text based on the input data.\n",
    "\n",
    "In particular, the tokenizer is set up to handle GPT-2’s requirements (using the EOS token as padding), and the dataset is prepared for causal language modeling, where the input IDs and labels are identical. During training, metrics like accuracy and loss are tracked, and the model is saved at the specified output directory with a timestamp, enabling consistent versioning and retrieval of the latest trained model. The accompanying `load_gpt2()` function allows reloading the trained GPT-2 model for further inference or evaluation tasks..</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/22/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a620ad-6870-477c-a98e-c229b64ff23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "def train_gpt2(train_texts, test_texts, epochs):\n",
    "    print(\"Training GPT-2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a padding token, use EOS token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenizer(train_texts, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "    test_encodings = tokenizer(test_texts, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "    # Set the labels to be the same as input IDs for causal language modeling\n",
    "    train_encodings['labels'] = train_encodings['input_ids'].clone()\n",
    "    test_encodings['labels'] = test_encodings['input_ids'].clone()\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(GPT2_PATH, f\"gpt2_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./gpt2_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU-only\n",
    "        fp16=torch.cuda.is_available(),  # Enable fp16 (mixed precision) if using CUDA\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer with both train and eval datasets\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset  # Add eval dataset for evaluation\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"GPT-2 model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer\n",
    "\n",
    "\n",
    "# Load latest GPT-2 model\n",
    "def load_gpt2():\n",
    "    latest_dir = get_latest_model_dir(GPT2_PATH)\n",
    "    if latest_dir:\n",
    "        print(f\"Loading GPT-2 model from {latest_dir}\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(latest_dir).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_dir)\n",
    "        return model, tokenizer\n",
    "    else:\n",
    "        print(\"No pre-trained GPT-2 model found.\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe592874-81da-4a09-961e-b6e02c3dcdc2",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - ELECTRA Model Training and Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is dedicated to training and evaluating a pre-trained ELECTRA model for sequence classification tasks, specifically to distinguish between real and fake news. The code begins by initializing the ELECTRA tokenizer and model for sequence classification. It then tokenizes and prepares the training and testing datasets with labels for supervised learning.\n",
    "\n",
    "The training process is set up with parameters such as batch size, learning rate, and evaluation frequency, tailored to optimize performance on a CPU. The model is trained to adjust its weights to classify text into binary categories based on the given dataset. Evaluation metrics, such as accuracy, are tracked at each epoch to assess model performance. After training, the model and tokenizer are saved to a specified output directory with a timestamp, providing structured version control.\n",
    "\n",
    "The `load_electra()` function is included to load the latest trained model from the output directory, facilitating model reuse for inference or further evaluation tasks.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/22/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8e73f-77b3-4bac-b1b4-24451bcebcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# ELECTRA Training Function\n",
    "def train_electra(train_texts, train_labels, test_texts, test_labels, epochs):\n",
    "    print(\"Training ELECTRA\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=2).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels, dtype=torch.long)  # Corrected to use train_labels\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels, dtype=torch.long)  # Corrected to use test_labels\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(ELECTRA_PATH, f\"electra_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./electra_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"ELECTRA model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer\n",
    "\n",
    "# Load latest ELECTRA model\n",
    "def load_electra():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(ELECTRA_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ELECTRA_PATH)\n",
    "    print(f\"ELECTRA model loaded from {ELECTRA_PATH}\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdafdbe-afc3-41b7-b3ec-7c6bfbe29200",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - LLAMA Model Training and Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is focused on training and evaluating a LLAMA model for causal language modeling tasks. It begins by setting up the LLAMA tokenizer and model to process and learn from a given dataset. The code tokenizes and prepares the data for training and evaluation, where each text sample is treated as input for the model to learn coherent text generation patterns.\n",
    "\n",
    "The training configuration includes parameters such as batch size, accumulation steps, and learning rate optimized for CPU-based training. During training, the model’s performance is evaluated at the end of each epoch to monitor progress, and the best-performing model checkpoint is saved. This process is specifically tailored for text generation tasks, enabling the model to generate text that aligns with the context of the training data.\n",
    "\n",
    "After training, the model and tokenizer are saved in an output directory with a timestamp, providing an organized and versioned storage structure. The `load_llama()` function enables reloading the trained LLAMA model for subsequent inference or evaluation tasks.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/22/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6fdd1f7-e4aa-4ac0-bd32-1f2ca192a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# LLAMA Training Function\n",
    "# Public LLAMA model training function\n",
    "def train_llama(train_texts, test_texts, epochs):\n",
    "    # print(\"Training LLAMA\")\n",
    "    # token = \"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\"  # Replace with your actual Hugging Face token\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "    # model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(LLAMA_PATH, f\"llama_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./llama_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        bf16=False,  # Set to False for CPU training\n",
    "        dataloader_num_workers=3\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"LLAMA model saved to {output_dir}\")\n",
    "\n",
    "# Load latest LLAMA model\n",
    "def load_llama():\n",
    "    model = AutoModelForCausalLM.from_pretrained(LLAMA_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "    print(f\"LLAMA model loaded from {LLAMA_PATH}\")\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4e59f-0c00-4ca2-9556-d722aa800cfc",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - OPT Model Training and Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is focused on training and evaluating the OPT model, a causal language model, for text generation tasks. The workflow involves initializing the OPT tokenizer and model, processing the training and testing datasets, and configuring training parameters suited for CPU-based execution. Text sequences are tokenized and structured into training and evaluation datasets, allowing the model to learn and generate relevant text based on input sequences.\n",
    "\n",
    "The training configuration includes parameters such as batch size, gradient accumulation steps, and evaluation frequency. These settings optimize the training process to yield accurate language generation on text data. Each epoch’s performance is evaluated, with the best model checkpoint saved automatically to an output directory with a timestamp, providing a structured versioning system.\n",
    "\n",
    "The `load_opt()` function is provided to reload the latest trained model for further inference or evaluation.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/22/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5f2f74-6e37-4af4-8cd0-48d0ce52f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "# OPT Training Function\n",
    "def train_opt(train_texts, test_texts, epochs):\n",
    "    print(\"Training OPT\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\")  # Model stays on CPU\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(OPT_PATH, f\"opt_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./opt_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        bf16=False,  # bf16 is only for GPU, so set this to False\n",
    "        dataloader_num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"OPT model saved to {output_dir}\")\n",
    "    \n",
    "# Load latest OPT model\n",
    "def load_opt():\n",
    "    model = AutoModelForCausalLM.from_pretrained(OPT_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(OPT_PATH)\n",
    "    print(f\"OPT model loaded from {OPT_PATH}\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f0216-9ce8-45fc-a1f8-404c01998140",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Hybrid Detection Model with DistilBERT and GPT-2</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to detect fake news by leveraging a hybrid approach using two models: DistilBERT and GPT-2. The process begins with using DistilBERT as a classifier to make an initial prediction on the input text. Then, GPT-2 generates a transformed version of the text based on the input, which is subsequently re-evaluated by DistilBERT. This combination provides a multi-step analysis of the text, improving reliability by incorporating both classification and generative steps in the detection process.</p>\n",
    "\n",
    "<p>To implement this hybrid approach, the code initializes both the DistilBERT and GPT-2 tokenizers and models. After the initial DistilBERT prediction, GPT-2 generates a related text sample, which DistilBERT re-evaluates. A cosine similarity measure is calculated between the embeddings of the original and GPT-2-generated texts to assess content similarity, with a specified threshold determining whether the text is classified as real or fake news. This similarity score further strengthens the model’s accuracy by providing an additional layer of verification.</p>\n",
    "\n",
    "<p>The code outputs “Fake News Detected” or “Real News Detected” based on DistilBERT's predictions and the cosine similarity check. This approach balances the strengths of a classifier and a language model, offering a more comprehensive detection system.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Mallikarjuna Reddy Bobbala</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/23/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc7635-b8a5-4fba-80fc-c3f682f1da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Detection Model with DistilBERT and GPT-2\n",
    "def detect_with_distilbert_gpt2(text, bert_model, bert_tokenizer, gpt_model, gpt_tokenizer, similarity_threshold=0.77):\n",
    "    # Text preprocessing\n",
    "    text = text_preprocessing(text)\n",
    "    # BERT prediction\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    # GPT-2 text generation\n",
    "    gpt_inputs = gpt_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    gpt_outputs = gpt_model.generate(gpt_inputs, max_length=100, pad_token_id=gpt_tokenizer.eos_token_id)\n",
    "    generated_text = gpt_tokenizer.decode(gpt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # BERT prediction on GPT-2-generated text\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]  # [CLS] token embedding\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac98fa9-5329-43c5-98d3-6e3073e1d2fb",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Hybrid Detection Model with DistilBERT and LLAMA</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to detect fake news using a hybrid approach that combines DistilBERT and LLAMA. The method begins with DistilBERT making an initial classification prediction on the input text, indicating whether it might be real or fake news. Following this, LLAMA generates an alternative version of the input text, which is then fed back into DistilBERT for a secondary prediction. This layered approach leverages both the discriminative capabilities of DistilBERT and the generative abilities of LLAMA to strengthen the detection process.</p>\n",
    "\n",
    "<p>In particular, the model performs an initial DistilBERT prediction, then uses LLAMA to generate a related text sequence based on the original input. The DistilBERT model is then applied again to classify the generated text. Cosine similarity is calculated between the embeddings of the original and generated texts, adding an additional layer of verification. If the similarity score is below a specified threshold, or if DistilBERT’s predictions indicate fake news, the text is classified as such. This technique improves the reliability of fake news detection by integrating classification with generative language processing.</p>\n",
    "\n",
    "<p>The function outputs either “Fake News Detected” or “Real News Detected” based on the combined model predictions and similarity assessment. This hybrid structure is intended to enhance the robustness of fake news detection by validating initial predictions with generated content analysis.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/30/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfadee1f-58dc-45a9-917c-0dd2cb190cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Detection Function for DistilBERT + LLAMA\n",
    "def detect_with_distilbert_llama(text, bert_model, bert_tokenizer, llama_model, llama_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    llama_inputs = llama_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    llama_outputs = llama_model.generate(llama_inputs, max_length=100, pad_token_id=llama_tokenizer.eos_token_id)\n",
    "    generated_text = llama_tokenizer.decode(llama_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af0daf-59f1-4413-9a14-5bf03ec95779",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Hybrid Detection Model with DistilBERT and OPT</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is focused on detecting fake news by using a hybrid approach with DistilBERT and OPT. The method initiates with DistilBERT making a preliminary classification prediction on the input text, identifying it as potential real or fake news. Following this, OPT generates a variant of the input text, which is subsequently re-evaluated by DistilBERT for a secondary classification. This multi-step approach capitalizes on both DistilBERT’s discriminative power and OPT’s generative capabilities to increase the robustness of the detection system.</p>\n",
    "\n",
    "<p>The process involves an initial classification by DistilBERT, after which OPT generates a related text sequence based on the original input. DistilBERT then classifies this generated text, with a cosine similarity score calculated between the embeddings of the original and generated texts. This similarity measurement helps reinforce the model’s decision, as texts deemed too dissimilar to the input are more likely to indicate fake content. If DistilBERT's predictions flag the text as fake or the similarity is below a specified threshold, the function classifies the text as “Fake News Detected.”</p>\n",
    "\n",
    "<p>This function outputs “Fake News Detected” or “Real News Detected” based on the combined outcomes from both models. By leveraging OPT’s text generation with DistilBERT’s classification, this code cell block provides a layered detection mechanism that enhances the credibility of fake news predictions.</p>\n",
    "\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/30/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d71f18-1aa3-4922-828e-116972cb0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Detection Function for DistilBERT + OPT\n",
    "def detect_with_distilbert_opt(text, bert_model, bert_tokenizer, opt_model, opt_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    opt_inputs = opt_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    opt_outputs = opt_model.generate(opt_inputs, max_length=100, pad_token_id=opt_tokenizer.eos_token_id)\n",
    "    generated_text = opt_tokenizer.decode(opt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c282c3-feea-41b8-a9cb-34e47c90797c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Hybrid Detection Model with DistilBERT and ELECTRA</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to detect fake news using a hybrid approach with DistilBERT and ELECTRA. The workflow begins by using DistilBERT to perform an initial classification of the input text, identifying whether it might be real or fake. Following this, ELECTRA generates a transformed version of the input, which is then re-evaluated by DistilBERT. This combination allows for both the classifier’s discriminative power and the generative capabilities of ELECTRA to be leveraged, enhancing the model’s robustness in distinguishing fake news.</p>\n",
    "\n",
    "<p>The hybrid detection process involves an initial classification by DistilBERT, followed by ELECTRA generating a modified text version based on the input. This generated text is then classified again by DistilBERT. To further strengthen the model’s decision, a cosine similarity is calculated between the embeddings of the original and generated texts. A similarity score below a specified threshold, or an initial classification as fake by DistilBERT, results in the text being marked as fake news. This approach offers a multi-layered verification system that improves detection reliability.</p>\n",
    "\n",
    "<p>The function outputs either “Fake News Detected” or “Real News Detected” based on the combined outcomes of DistilBERT’s predictions and the similarity assessment. By integrating the strengths of both DistilBERT and ELECTRA, this hybrid model aims to provide a robust and reliable fake news detection framework.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/30/2024 - Completed Code/ for training and Evaluating model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90be6f-d337-417d-bb4a-55a1e2c5c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Detection Function for DistilBERT + ELECTRA\n",
    "def detect_with_distilbert_electra(text, bert_model, bert_tokenizer, electra_model, electra_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    electra_inputs = electra_tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True).to(device)\n",
    "    electra_outputs = electra_model(electra_inputs['input_ids'], attention_mask=electra_inputs['attention_mask'])\n",
    "    generated_text = electra_tokenizer.decode(electra_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:,0,:]\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:,0,:]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 1 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59dce8-e18d-4270-8dfd-f612f3ccb790",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Model Training Phase</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to train language models on a given dataset, using a consistent framework for initialization, training, and evaluation. The purpose of this approach is to create a flexible, reusable structure for fine-tuning different models in sequence, allowing comparison of performance across models and easy adaptation for future models. This code block supports models such as DistilBERT, GPT-2, LLAMA, ELECTRA, and OPT, each trained with similar parameters for a standardized evaluation and tuning process.</p>\n",
    "\n",
    "<p> Each model is trained over a specified number of epochs on training and test datasets, with progress saved to a designated output directory. This standardized setup supports systematic model comparisons, and additional models can be added in the future with minimal changes to the workflow.</p>\n",
    "\n",
    "<p>Outputs from each training run, including trained models and tokenizers, are saved in separate directories for structured, versioned storage.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Mallikarjuna Reddy Bobbala</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/24/2024 - Comeplete training init code for distilBert model</li>\n",
    "</ul>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Steve Mwika</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/30/2024 - Complete Training Code for the models</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66b256-8f6a-4ea7-b3dc-625505a9783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training Phase\n",
    "bert_trainer, bert_model, bert_tokenizer = train_distilbert(train_texts, train_labels, test_texts, test_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08d843-f46d-49e6-9126-b6d1c36a8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GPT-2 model\n",
    "gpt2_trainer, gpt2_model, gpt2_tokenizer = train_gpt2(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24941fa0-d9c1-402c-a3ce-b230391fd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LLAMA model\n",
    "llama_trainer, llama_model, llama_tokenizer = train_llama(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8860e-6a2b-43c9-a962-19424c295463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ELECTRA model\n",
    "electra_trainer, electra_model, electra_tokenizer = train_electra(train_texts, train_labels, test_texts, test_labels, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfd36a-c2b5-4954-ad45-7468813bcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train OPT model\n",
    "opt_trainer, opt_model, opt_tokenizer = train_opt(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5396d-de65-47ab-be4e-8f4e916278ae",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - DistilBERT Model Evaluation on BuzzFeed Dataset</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to evaluate the performance of a trained model on an external dataset, in this case, the BuzzFeed dataset. The evaluation process includes loading and preprocessing the data, running predictions with the trained DistilBERT model, and calculating various metrics to assess model accuracy and reliability.</p>\n",
    "\n",
    "<p>The process involves loading the BuzzFeed real and fake news datasets, assigning binary labels (1 for real and 0 for fake), and preprocessing the text for compatibility with the model. Once the data is prepared, it is run through the trained DistilBERT model to obtain predictions. Key evaluation metrics such as accuracy, ROC AUC score, log loss, and confusion matrix are computed to give insight into the model’s performance. The metrics and visualizations, such as ROC and Precision-Recall curves, are saved in an organized output directory for structured storage and review.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Shuainan (Eric) Liu</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/31/2024 - Completed Code For Model Evaluation</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "930f7475-b8b2-45e3-b8dd-555bc39202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Load the BuzzFeed datasets\n",
    "buzzfeed_real_df = pd.read_csv('./data/BuzzFeed_real_news_content.csv')\n",
    "buzzfeed_fake_df = pd.read_csv('./data/BuzzFeed_fake_news_content.csv')\n",
    "\n",
    "# Add 'label' column: 1 for real news, 0 for fake news\n",
    "buzzfeed_real_df['label'] = 1\n",
    "buzzfeed_fake_df['label'] = 0\n",
    "\n",
    "# Retain only relevant columns ('title', 'text', 'label') and drop rows with missing text\n",
    "buzzfeed_real_df = buzzfeed_real_df[['text', 'label']].dropna(subset=['text'])\n",
    "buzzfeed_fake_df = buzzfeed_fake_df[['text', 'label']].dropna(subset=['text'])\n",
    "\n",
    "# Combine real and fake datasets into one\n",
    "buzzfeed_combined_df = pd.concat([buzzfeed_real_df, buzzfeed_fake_df], ignore_index=True)\n",
    "# Apply preprocessing to 'text' column\n",
    "buzzfeed_combined_df['text'] = buzzfeed_combined_df['text'].apply(preprocess_text)\n",
    "# Display the cleaned data\n",
    "buzzfeed_combined_df.sample()\n",
    "\n",
    "# 7. Detection Phase\n",
    "# Load trained models and tokenizers\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "\n",
    "# Prepare the data for evaluation\n",
    "texts = buzzfeed_combined_df['text'].tolist()\n",
    "labels = buzzfeed_combined_df['label'].tolist()\n",
    "\n",
    "# Store predictions and probabilities for evaluation\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# Run inference on each sample\n",
    "with torch.no_grad():\n",
    "    for text in texts:\n",
    "        # Tokenize and get model predictions\n",
    "        inputs = distilbert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "        outputs = distilbert_model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_label = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "        probabilities.append(probs.cpu().numpy()[0][1])  # Probability of class 1 (real)\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for compatibility with metrics functions\n",
    "y_true = np.array(labels)\n",
    "y_pred = np.array(predictions)\n",
    "y_prob = np.array(probabilities)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "metrics_log = {\n",
    "    \"Buzzfeed_Log Loss\": log_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Brier Score Loss\": brier_score_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "    \"Buzzfeed_Cohen's Kappa Score\": cohen_kappa_score(y_true, y_pred),\n",
    "    \"Buzzfeed_ROC AUC Score\": roc_auc_score(y_true, y_prob),\n",
    "    \"Buzzfeed_Accuracy Score\": accuracy_score(y_true, y_pred),\n",
    "}\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Print the metrics log\n",
    "print(\"Buzzfeed_Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Generate and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title(\"ROC Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_roc_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title(\"Precision-Recall Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_precision_recall_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Summarize metrics in a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_log, index=[0])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_summary.csv\"), index=False)\n",
    "\n",
    "print(\"Evaluation complete. Metrics and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091f47b-d98d-427c-a015-208e3af50f09",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - DistilBERT Fake News Detection on Custom Data</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to use the DistilBERT model for detecting fake news through direct classification. It involves initializing DistilBERT and its tokenizer, configuring the model for inference on a given text, and setting a probability threshold for determining whether a news sample is classified as real or fake.</p>\n",
    "\n",
    "<p>The process includes a sample test case drawn from a well-known dataset to illustrate how DistilBERT performs on text inputs with controversial or sensitive content, enhancing the model's application in identifying misleading or potentially harmful news.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook\">BERT-Based Fake News Detector - Kaggle</a></li>\n",
    "    <p>Took the sample Custom Test case</p>\n",
    "    <blockquote>\n",
    "        <p>test_text=\"Cop Shares Racist Meme About Michelle Obama; Now That Cop Is Having A VERY Bad Day (IMAGES)After the election of Donald Trump many folks seem to see it as a permission slip to be as racist and vile as possible. However, here s the thing, you re still going to get called out as racist and vile. And one Alabama police officer just found this out the hard way.According to the Washington Post: Talladega Police Officer Joel Husk was terminated Wednesday for violating the department s social media and code of conduct policies, City Manager Patrick Bryant said. What did he do? So glad you asked: Husk had posted several memes on his Facebook page, including one showing Obama and Melania Trump.  Fluent in Slovenian, English, French, Serbian, and German,  it said over Trump s photo. Over Obama s, it read:  Fluent in Ghetto. Not only that, he posted several extraordinarily racist memes:via Washington Postvia Washington PostAccording to the City Manager, the statements were  deemed to be biased or racially insensitive or derogatory  and because of that, they  have to take action to correct it. If you re going to be a police officer and serve all the public, you can t assume black people standing up for their rights are equivalent to the KKK. That s about the most horrific equivalence imaginable.Also, according to WaPo: Husk, 37, who had been with the department for about two and a half years, had also shared a meme showing President Obama with the words:  Was Dallas a terrorist attack? Yes! Carried out by Obama s own homegrown terrorist group! Which is a blatant lie and anyone who were to feel that way belongs nowhere near law enforcement. The city took the proper action letting this racist cop go, and hopefully it will be an example to police departments all over the country that this sort of behavior simply cannot be tolerated.Trump s election must not be allowed to serve as a permission slip to bigots everywhere that it s fine to be as awful as possible, because here in the land of the free and the home of the brave, everyone is protected. Everyone, regardless of color, class, gender, sexual orientation, or creed.Featured Photo by Chip Somodevilla/Getty Images'\"</p>\n",
    "    </blockquote>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Shuainan (Eric) Liu</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>10/31/2024 - Completed Code for Distilbert model Evaluation with custom Data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff9ef6-2f0a-4dc3-b142-30393bd18d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "# Detection function using DistilBERT\n",
    "def detect_with_distilbert(text, model, tokenizer, threshold=0.5):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    fake_prob = probs[0][0].item()\n",
    "    real_prob = probs[0][1].item()\n",
    "    prediction = 1 if real_prob >= threshold else 0\n",
    "    return prediction, real_prob  # returning probability for ROC and PR curves\n",
    "\n",
    "\n",
    "test_text=\"Cop Shares Racist Meme About Michelle Obama; Now That Cop Is Having A VERY Bad Day (IMAGES)After the election of Donald Trump many folks seem to see it as a permission slip to be as racist and vile as possible. However, here s the thing, you re still going to get called out as racist and vile. And one Alabama police officer just found this out the hard way.According to the Washington Post: Talladega Police Officer Joel Husk was terminated Wednesday for violating the department s social media and code of conduct policies, City Manager Patrick Bryant said. What did he do? So glad you asked: Husk had posted several memes on his Facebook page, including one showing Obama and Melania Trump.  Fluent in Slovenian, English, French, Serbian, and German,  it said over Trump s photo. Over Obama s, it read:  Fluent in Ghetto. Not only that, he posted several extraordinarily racist memes:via Washington Postvia Washington PostAccording to the City Manager, the statements were  deemed to be biased or racially insensitive or derogatory  and because of that, they  have to take action to correct it. If you re going to be a police officer and serve all the public, you can t assume black people standing up for their rights are equivalent to the KKK. That s about the most horrific equivalence imaginable.Also, according to WaPo: Husk, 37, who had been with the department for about two and a half years, had also shared a meme showing President Obama with the words:  Was Dallas a terrorist attack? Yes! Carried out by Obama s own homegrown terrorist group! Which is a blatant lie and anyone who were to feel that way belongs nowhere near law enforcement. The city took the proper action letting this racist cop go, and hopefully it will be an example to police departments all over the country that this sort of behavior simply cannot be tolerated.Trump s election must not be allowed to serve as a permission slip to bigots everywhere that it s fine to be as awful as possible, because here in the land of the free and the home of the brave, everyone is protected. Everyone, regardless of color, class, gender, sexual orientation, or creed.Featured Photo by Chip Somodevilla/Getty Images'\"\n",
    "\n",
    "# Initialize DistilBERT model and tokenizer\n",
    "device = torch.device(\"cpu\")\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Predict and print result for custom data\n",
    "result, real_prob = detect_with_distilbert(test_text, distilbert_model, distilbert_tokenizer)\n",
    "print(f\"Prediction for custom data: {result} (Real News Probability: {real_prob:.2f})\")\n",
    "\n",
    "if result == 0:\n",
    "    print(\"News is Fake\")\n",
    "else:\n",
    "    print(\"News is Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c17ee-c524-40fe-bc91-90662c5e401b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - DistiliBert Model Evaluation on ISOT Fake News Dataset</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to evaluate the DistilBERT model's performance on the ISOT Fake News Dataset, quantifying the model’s accuracy in distinguishing real and fake news. By using established metrics and visualizations, this evaluation framework is structured to yield insights into the model's strengths and weaknesses and can be easily adapted to similar datasets in future analyses.</p>\n",
    "\n",
    "<p>The code processes the test dataset through the trained DistilBERT model, capturing predictions and probabilities, then calculates key metrics such as accuracy, F1 score, ROC AUC, log loss, and Brier score. Additionally, the code generates and saves a confusion matrix, ROC curve, and Precision-Recall curve for visual insight into performance. Metrics and plots are stored in an organized output directory, allowing for consistent documentation and review.</p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Shuainan (Eric) Liu</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/01/2024 - Completed Code for Distilbert model Evaluation with Trained Courpus</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "306bb884-9d17-4104-9f33-fb7fc03e0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "\n",
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = test_labels\n",
    "y_pred = []\n",
    "y_score = []\n",
    "\n",
    "# Run detection on test data\n",
    "for text in test_texts:\n",
    "    pred_label, real_prob = detect_with_distilbert(text, distilbert_model, distilbert_tokenizer)\n",
    "    y_pred.append(pred_label)\n",
    "    y_score.append(real_prob)  # For ROC and Precision-Recall curves\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "log_loss_value = log_loss(y_true, y_score)\n",
    "brier_score = brier_score_loss(y_true, y_score)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "# Log and save metrics\n",
    "metrics_log = {\n",
    "    \"ISOT_Fake_News_Dataset_Log Loss\": log_loss_value,\n",
    "    \"ISOT_Fake_News_Dataset_Brier Score Loss\": brier_score,\n",
    "    \"ISOT_Fake_News_Dataset_Matthews Correlation Coefficient\": mcc,\n",
    "    \"ISOT_Fake_News_Dataset_Cohen's Kappa Score\": kappa,\n",
    "    \"ISOT_Fake_News_Dataset_ROC AUC Score\": roc_auc,\n",
    "    \"ISOT_Fake_News_Dataset_Accuracy Score\": accuracy,\n",
    "    \"ISOT_Fake_News_Dataset_F1 Score\": f1\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"ISOT_Fake_News_Dataset Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame(list(metrics_log.items()), columns=[\"Metric\", \"Score\"])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_summary.csv\"), index=False)\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_confusion_matrix_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title('ROC Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_roc_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title('Precision-Recall Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_precision_recall_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Evaluation complete. Metrics, logs, and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8172d82-1f3b-4514-9c65-5413f59f629e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Hybrid Model Detection Evaluation</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>This code cell block is designed to evaluate the performance of hybrid detection models that combine DistilBERT with various generative models (GPT-2, LLAMA, ELECTRA, and OPT) for fake news detection. By using a combined approach, these hybrid models leverage DistilBERT’s classification accuracy along with each generative model’s text generation capabilities to enhance fake news detection.</p>\n",
    "\n",
    "<p>For each hybrid model, the code applies DistilBERT to make an initial prediction on a sample text, followed by text generation from the paired generative model. DistilBERT then re-evaluates this generated text to cross-check the initial prediction. Metrics such as accuracy, F1 score, ROC AUC, and a detailed classification report are calculated for each hybrid model and stored for review. Additionally, the code generates and saves visualization outputs, including confusion matrices, ROC curves, and Precision-Recall curves, for each model configuration. </p>\n",
    "\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/norhanahmed34/deberta-tensorflow-final-2</li>\n",
    "    <li>https://www.kaggle.com/code/evilspirit05/bert-based-fake-news-detector/notebook</li>\n",
    "    <li>https://github.com/Navy10021/FakeLense/blob/main/code/model_code.py</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Shuainan (Eric) Liu</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/01/2024 - Completed Code code For future Hybrid Model Evaluation</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94531b6e-9767-44c8-ac22-25cb32a03fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cells for running and evaluating the solution\n",
    "\n",
    "\n",
    "# Load generation models\n",
    "gpt2_model, gpt2_tokenizer = load_gpt2()\n",
    "llama_model, llama_tokenizer = load_llama()\n",
    "opt_model, opt_tokenizer = load_opt()\n",
    "\n",
    "# Dictionary to store models for detection\n",
    "models = {\n",
    "    'distilbert_gpt2': (gpt2_model, gpt2_tokenizer, detect_with_distilbert_gpt2),\n",
    "    'distilbert_electra': (electra_model, electra_tokenizer, detect_with_distilbert_electra),\n",
    "    'distilbert_opt': (opt_model, opt_tokenizer, detect_with_distilbert_opt)\n",
    "}\n",
    "\n",
    "# Prepare test data and labels\n",
    "test_data = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "# Initialize results dictionary to store metrics for each combination\n",
    "results = {}\n",
    "\n",
    "for name, (gen_model, gen_tokenizer, detect_func) in models.items():\n",
    "    print(f\"Running detection for: {name}\")\n",
    "\n",
    "    y_true = test_data['label'].values\n",
    "    y_pred = []\n",
    "    y_score = []  # Store similarity scores for ROC and Precision-Recall curves\n",
    "\n",
    "    # Perform detection on test data\n",
    "    for text in test_data['text']:\n",
    "        result = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        pred_label = 1 if result == \"Real News Detected.\" else 0\n",
    "        y_pred.append(pred_label)\n",
    "\n",
    "        # Get similarity score from the detection function\n",
    "        # Modify detect_func to return score alongside label\n",
    "        _, similarity_score = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        y_score.append(similarity_score)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'], output_dict=True)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_true, y_pred, target_names=['Fake', 'Real'])}\")\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'confusion_matrix_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'roc_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n",
    "    plt.title(f'Precision-Recall Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'precision_recall_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "for name, metrics in results.items():\n",
    "    pd.DataFrame(metrics).to_csv(os.path.join(OUTPUT_DIR, name, f\"{name}_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2ac1e-ecb8-4868-851a-ba2721e9a861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

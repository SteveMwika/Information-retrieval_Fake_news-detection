{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298c9f0c-fb24-4bfb-b02d-ed399530fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\steve\\anaconda3\\envs\\ir_2024\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "#packages to import to run the code in the Jupyter Notebook\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, f1_score, ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "!pip install datasets\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "from transformers import EarlyStoppingCallback\n",
    "import math\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import GPT2Config\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25039075-9514-4ca7-bf95-1578c0d88cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f40148-489b-4e7c-a36b-78ac6f8eea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "# nltk.data.clear_cache()\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0171582a-6f72-4cec-a0d7-da2e407d6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')  # Tokenizer to remove punctuation by splitting on word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd470f2-dbfd-4a4d-83cb-52fe5086f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "DISTILBERT_PATH = './model/distilbert'\n",
    "LLAMA_PATH = './model/llama'\n",
    "OPT_PATH = './model/opt'\n",
    "GPT2_PATH = './model/gpt2'\n",
    "ELECTRA_PATH = './model/electra'\n",
    "\n",
    "# Create model directories if they don't exist\n",
    "os.makedirs(DISTILBERT_PATH, exist_ok=True)\n",
    "os.makedirs(ELECTRA_PATH, exist_ok=True)\n",
    "os.makedirs(LLAMA_PATH, exist_ok=True)\n",
    "os.makedirs(OPT_PATH, exist_ok=True)\n",
    "os.makedirs(GPT2_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define directories for saving outputs\n",
    "OUTPUT_DIR = './outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "COMBINATIONS = ['distilbert_gpt2', 'distilbert_llama', 'distilbert_opt']\n",
    "for combination in COMBINATIONS:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, combination), exist_ok=True)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 30\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cfe795-35a9-412c-a7ad-906a5ee0ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Check if text is not a string\n",
    "        text = \"\"  # Replace non-string values with an empty string\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"â\\w+|â€™|â€œ|â€|[^\\x00-\\x7F]+\", \"\", text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove content in brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a10948-91e2-413e-be0f-3242b09b6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine all datasets\n",
    "file_paths = [\n",
    "    \"./data/Fake.csv\",\n",
    "    \"./data/True.csv\",\n",
    "    \"./data/BuzzFeed_fake_news_content.csv\",\n",
    "    \"./data/BuzzFeed_real_news_content.csv\",\n",
    "    \"./data/PolitiFact_fake_news_content.csv\",\n",
    "    \"./data/PolitiFact_real_news_content.csv\",\n",
    "    \"./data/cleaned_train.csv\",\n",
    "    \"./data/fake_or_real_news.csv\"\n",
    "]\n",
    "\n",
    "# Assign labels for files with only \"text\" column\n",
    "label_map = {\n",
    "    \"./data/Fake.csv\": 0,\n",
    "    \"./data/True.csv\": 1,\n",
    "    \"./data/BuzzFeed_fake_news_content.csv\": 0,\n",
    "    \"./data/BuzzFeed_real_news_content.csv\": 1,\n",
    "    \"./data/PolitiFact_fake_news_content.csv\": 0,\n",
    "    \"./data/PolitiFact_real_news_content.csv\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b124ea1-14bb-4669-af60-a6fffad29072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_file(file_path, label=None):\n",
    "    print(f\"\\nProcessing file: {file_path}\")\n",
    "    try:\n",
    "        # Try reading the file with UTF-8 encoding\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"File {file_path} loaded successfully with utf-8 encoding.\")\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback to ISO-8859-1 encoding \n",
    "        df = pd.read_csv(file_path, encoding='ISO-8859-1', low_memory=False)\n",
    "        print(f\"File {file_path} loaded with ISO-8859-1 encoding.\")\n",
    "\n",
    "    # Debugging: Print initial column names\n",
    "    print(f\"Columns in {file_path}: {df.columns}\")\n",
    "\n",
    "    # Remove any unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Handle files with only \"text\" column\n",
    "    if 'text' in df.columns and 'label' not in df.columns:\n",
    "        print(f\"File {file_path} has only 'text' column. Assigning label: {label}\")\n",
    "        df['label'] = label  # Assign label based on the file (e.g., fake or real)\n",
    "\n",
    "    # Handle files with \"title\" and \"text\" columns\n",
    "    if 'title' in df.columns and 'text' in df.columns:\n",
    "        print(f\"File {file_path} has 'title' and 'text' columns. Combining them.\")\n",
    "        df['text'] = df['title'].fillna('') + \" \" + df['text'].fillna('')\n",
    "        df = df[['text', 'label']]  # Keep only necessary columns\n",
    "\n",
    "    # Debugging: Check unique label values before mapping\n",
    "    #print(f\"Unique label values before mapping: {df['label'].unique()}\")\n",
    "\n",
    "    # Map labels to binary values if they are in string format\n",
    "    if 'label' in df.columns and df['label'].dtype == 'object':\n",
    "        print(f\"Mapping string labels to binary values for {file_path}.\")\n",
    "        df['label'] = df['label'].map({'REAL': 1, 'FAKE': 0, 'real': 1, 'fake': 0})\n",
    "\n",
    "    # Debugging: Check unique label values after mapping\n",
    "    print(f\"Unique label values after mapping: {df['label'].unique()}\")\n",
    "\n",
    "    # Drop rows with missing text or label\n",
    "    print(f\"Initial shape of dataset: {df.shape}\")\n",
    "    df.dropna(subset=['text', 'label'], inplace=True)\n",
    "\n",
    "    # Ensure 'label' contains only 0 or 1\n",
    "    df['label'] = pd.to_numeric(df['label'], errors='coerce')  # Convert to numeric\n",
    "    df = df[df['label'].isin([0, 1])]  # Keep only rows where label is 0 or 1\n",
    "    print(f\"Shape after filtering invalid labels: {df.shape}\")\n",
    "\n",
    "    # Ensure 'text' column contains strings\n",
    "    if 'text' in df.columns:\n",
    "        df['text'] = df['text'].astype(str)\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        df = df.dropna(subset=['label'])\n",
    "        df['label'] = df['label'].astype(int)\n",
    "\n",
    "    # Preprocess the text\n",
    "    print(f\"Preprocessing text for {file_path}.\")\n",
    "    df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "    # Debugging Outputs\n",
    "    print(f\"Processed head of the dataset for {file_path}:\\n\", df.head())\n",
    "    print(f\"Label value counts for {file_path}:\\n\", df['label'].value_counts(dropna=False))\n",
    "    print(f\"Final null value counts for {file_path}:\\n\", df.isnull().sum())\n",
    "\n",
    "    return df[['text', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3b3b48-56a2-496c-b694-800709af6e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: ./data/Fake.csv\n",
      "File ./data/Fake.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/Fake.csv: Index(['title', 'text', 'subject', 'date'], dtype='object')\n",
      "File ./data/Fake.csv has only 'text' column. Assigning label: 0\n",
      "File ./data/Fake.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [0]\n",
      "Initial shape of dataset: (23481, 2)\n",
      "Shape after filtering invalid labels: (23481, 2)\n",
      "Preprocessing text for ./data/Fake.csv.\n",
      "Processed head of the dataset for ./data/Fake.csv:\n",
      "                                                 text  label\n",
      "0  donald trump sends embarrassing new year eve m...      0\n",
      "1  drunk bragging trump staffer started russian c...      0\n",
      "2  sheriff david clarke becomes internet joke thr...      0\n",
      "3  trump obsessed even obamas name coded website ...      0\n",
      "4  pope francis called donald trump christmas spe...      0\n",
      "Label value counts for ./data/Fake.csv:\n",
      " label\n",
      "0    23481\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/Fake.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/True.csv\n",
      "File ./data/True.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/True.csv: Index(['title', 'text', 'subject', 'date'], dtype='object')\n",
      "File ./data/True.csv has only 'text' column. Assigning label: 1\n",
      "File ./data/True.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [1]\n",
      "Initial shape of dataset: (21417, 2)\n",
      "Shape after filtering invalid labels: (21417, 2)\n",
      "Preprocessing text for ./data/True.csv.\n",
      "Processed head of the dataset for ./data/True.csv:\n",
      "                                                 text  label\n",
      "0  u budget fight loom republican flip fiscal scr...      1\n",
      "1  u military accept transgender recruit monday p...      1\n",
      "2  senior u republican senator let mr mueller job...      1\n",
      "3  fbi russia probe helped australian diplomat ti...      1\n",
      "4  trump want postal service charge much amazon s...      1\n",
      "Label value counts for ./data/True.csv:\n",
      " label\n",
      "1    21417\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/True.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/BuzzFeed_fake_news_content.csv\n",
      "File ./data/BuzzFeed_fake_news_content.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/BuzzFeed_fake_news_content.csv: Index(['id', 'title', 'text', 'url', 'top_img', 'authors', 'source',\n",
      "       'publish_date', 'movies', 'images', 'canonical_link', 'meta_data'],\n",
      "      dtype='object')\n",
      "File ./data/BuzzFeed_fake_news_content.csv has only 'text' column. Assigning label: 0\n",
      "File ./data/BuzzFeed_fake_news_content.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [0]\n",
      "Initial shape of dataset: (91, 2)\n",
      "Shape after filtering invalid labels: (91, 2)\n",
      "Preprocessing text for ./data/BuzzFeed_fake_news_content.csv.\n",
      "Processed head of the dataset for ./data/BuzzFeed_fake_news_content.csv:\n",
      "                                                 text  label\n",
      "0  proof mainstream medium manipulating election ...      0\n",
      "1  charity clinton foundation distributed watered...      0\n",
      "2  hillary clinton administration may entirely ru...      0\n",
      "3  trump latest campaign promise may horrible one...      0\n",
      "4            website maintenance website maintenance      0\n",
      "Label value counts for ./data/BuzzFeed_fake_news_content.csv:\n",
      " label\n",
      "0    91\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/BuzzFeed_fake_news_content.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/BuzzFeed_real_news_content.csv\n",
      "File ./data/BuzzFeed_real_news_content.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/BuzzFeed_real_news_content.csv: Index(['id', 'title', 'text', 'url', 'top_img', 'authors', 'source',\n",
      "       'publish_date', 'movies', 'images', 'canonical_link', 'meta_data'],\n",
      "      dtype='object')\n",
      "File ./data/BuzzFeed_real_news_content.csv has only 'text' column. Assigning label: 1\n",
      "File ./data/BuzzFeed_real_news_content.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [1]\n",
      "Initial shape of dataset: (91, 2)\n",
      "Shape after filtering invalid labels: (91, 2)\n",
      "Preprocessing text for ./data/BuzzFeed_real_news_content.csv.\n",
      "Processed head of the dataset for ./data/BuzzFeed_real_news_content.csv:\n",
      "                                                 text  label\n",
      "0  another terrorist attack nycwhy still politica...      1\n",
      "1  donald trump drug big factor charlotte protest...      1\n",
      "2  obama un giving liberty enhances security amer...      1\n",
      "3  trump v clinton fundamental clash economy work...      1\n",
      "4  president obama veto 911 victim bill setting s...      1\n",
      "Label value counts for ./data/BuzzFeed_real_news_content.csv:\n",
      " label\n",
      "1    91\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/BuzzFeed_real_news_content.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/PolitiFact_fake_news_content.csv\n",
      "File ./data/PolitiFact_fake_news_content.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/PolitiFact_fake_news_content.csv: Index(['id', 'title', 'text', 'url', 'top_img', 'authors', 'source',\n",
      "       'publish_date', 'movies', 'images', 'canonical_link', 'meta_data'],\n",
      "      dtype='object')\n",
      "File ./data/PolitiFact_fake_news_content.csv has only 'text' column. Assigning label: 0\n",
      "File ./data/PolitiFact_fake_news_content.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [0]\n",
      "Initial shape of dataset: (120, 2)\n",
      "Shape after filtering invalid labels: (120, 2)\n",
      "Preprocessing text for ./data/PolitiFact_fake_news_content.csv.\n",
      "Processed head of the dataset for ./data/PolitiFact_fake_news_content.csv:\n",
      "                                                 text  label\n",
      "0  trump insulted million lost everything bush re...      0\n",
      "1  famous dog killed spot waited year owner retur...      0\n",
      "2  house oversight panel vote clinton chief conte...      0\n",
      "3  america tragically lost country music icon ple...      0\n",
      "4  monument battle new south nine year ago driver...      0\n",
      "Label value counts for ./data/PolitiFact_fake_news_content.csv:\n",
      " label\n",
      "0    120\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/PolitiFact_fake_news_content.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/PolitiFact_real_news_content.csv\n",
      "File ./data/PolitiFact_real_news_content.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/PolitiFact_real_news_content.csv: Index(['id', 'title', 'text', 'url', 'top_img', 'authors', 'source',\n",
      "       'publish_date', 'movies', 'images', 'canonical_link', 'meta_data'],\n",
      "      dtype='object')\n",
      "File ./data/PolitiFact_real_news_content.csv has only 'text' column. Assigning label: 1\n",
      "File ./data/PolitiFact_real_news_content.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [1]\n",
      "Initial shape of dataset: (120, 2)\n",
      "Shape after filtering invalid labels: (120, 2)\n",
      "Preprocessing text for ./data/PolitiFact_real_news_content.csv.\n",
      "Processed head of the dataset for ./data/PolitiFact_real_news_content.csv:\n",
      "                                                 text  label\n",
      "0  trump insulted million lost everything bush re...      1\n",
      "1  famous dog killed spot waited year owner retur...      1\n",
      "2  house oversight panel vote clinton chief conte...      1\n",
      "3  america tragically lost country music icon ple...      1\n",
      "4  monument battle new south nine year ago driver...      1\n",
      "Label value counts for ./data/PolitiFact_real_news_content.csv:\n",
      " label\n",
      "1    120\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/PolitiFact_real_news_content.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/cleaned_train.csv\n",
      "File ./data/cleaned_train.csv loaded with ISO-8859-1 encoding.\n",
      "Columns in ./data/cleaned_train.csv: Index(['id', 'title', 'author', 'text', 'label', 'Helper', 'KEEP'], dtype='object')\n",
      "File ./data/cleaned_train.csv has 'title' and 'text' columns. Combining them.\n",
      "Unique label values after mapping: [ 1.  0. nan]\n",
      "Initial shape of dataset: (24212, 2)\n",
      "Shape after filtering invalid labels: (20707, 2)\n",
      "Preprocessing text for ./data/cleaned_train.csv.\n",
      "Processed head of the dataset for ./data/cleaned_train.csv:\n",
      "                                                 text  label\n",
      "0  house dem aide didnt even see comeys letter ja...      1\n",
      "1  flynn hillary clinton big woman campus breitba...      0\n",
      "2  truth might get fired truth might get fired oc...      1\n",
      "3  15 civilian killed single u airstrike identifi...      1\n",
      "4  iranian woman jailed fictional unpublished sto...      1\n",
      "Label value counts for ./data/cleaned_train.csv:\n",
      " label\n",
      "1    10362\n",
      "0    10345\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/cleaned_train.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Processing file: ./data/fake_or_real_news.csv\n",
      "File ./data/fake_or_real_news.csv loaded successfully with utf-8 encoding.\n",
      "Columns in ./data/fake_or_real_news.csv: Index(['Unnamed: 0', 'title', 'text', 'label'], dtype='object')\n",
      "File ./data/fake_or_real_news.csv has 'title' and 'text' columns. Combining them.\n",
      "Mapping string labels to binary values for ./data/fake_or_real_news.csv.\n",
      "Unique label values after mapping: [0 1]\n",
      "Initial shape of dataset: (6335, 2)\n",
      "Shape after filtering invalid labels: (6335, 2)\n",
      "Preprocessing text for ./data/fake_or_real_news.csv.\n",
      "Processed head of the dataset for ./data/fake_or_real_news.csv:\n",
      "                                                 text  label\n",
      "0  smell hillary fear daniel greenfield shillman ...      0\n",
      "1  watch exact moment paul ryan committed politic...      0\n",
      "2  kerry go paris gesture sympathy u secretary st...      1\n",
      "3  bernie supporter twitter erupt anger dnc tried...      0\n",
      "4  battle new york primary matter primary day new...      1\n",
      "Label value counts for ./data/fake_or_real_news.csv:\n",
      " label\n",
      "1    3171\n",
      "0    3164\n",
      "Name: count, dtype: int64\n",
      "Final null value counts for ./data/fake_or_real_news.csv:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_data = pd.DataFrame()\n",
    "\n",
    "for file_path in file_paths:\n",
    "    label = label_map.get(file_path, None)  \n",
    "    df = load_and_preprocess_file(file_path, label=label)\n",
    "    final_data = pd.concat([final_data, df], ignore_index=True)\n",
    "\n",
    "# Shuffle and reset index\n",
    "final_data = final_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb0a316-134f-46d9-aeca-40e4bb4004f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  video breaking hillary clinton facing possible...      0\n",
      "1  jeddah airport targeted ansar allah missile se...      1\n",
      "2  neocon trotskyite hannity want america back tr...      1\n",
      "3  session border open breitbart attorney general...      0\n",
      "4  exclusive wife 911 victim pen letter donald tr...      0\n"
     ]
    }
   ],
   "source": [
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0929e030-3467-4093-bf3a-e80cdc33a04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    37201\n",
       "1    35161\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa4b5c7-24d9-4a8f-962d-154345dde487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2ea65a-5a6d-4963-817a-1815a0d9865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>donald trump president obama jk rowling friday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71517</th>\n",
       "      <td>new country woman minority hardest hit new cou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44062</th>\n",
       "      <td>nearly half briton back trump state visit youg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ruth bader ginsburg fan donald trump critique ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>rare public speech obama decries republican he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57053</th>\n",
       "      <td>russian expert collecting evidence antigovt ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>former u attorney clear intel conspired frame ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>misleading mainstream medium pushing false nar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53424</th>\n",
       "      <td>turkish u foreign minister speak phone amid vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>like mother like daughter chelsea clinton spre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "10931  donald trump president obama jk rowling friday...      0\n",
       "71517  new country woman minority hardest hit new cou...      1\n",
       "44062  nearly half briton back trump state visit youg...      1\n",
       "196    ruth bader ginsburg fan donald trump critique ...      0\n",
       "5009   rare public speech obama decries republican he...      1\n",
       "57053  russian expert collecting evidence antigovt ch...      1\n",
       "851    former u attorney clear intel conspired frame ...      0\n",
       "3501   misleading mainstream medium pushing false nar...      0\n",
       "53424  turkish u foreign minister speak phone amid vi...      1\n",
       "6366   like mother like daughter chelsea clinton spre...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6dd9ff-9119-405f-aaa1-bc62c481e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nigger libtards thought putting body camera leo going uncover treasure trove evidence order convict every cop u racist brutality charge exact opposite happened nigger obsessively aggressive behavior full display jewtube elsewhere world witness also cop nearly always shown using kit glove tactic order wrangle beast video perfect example female allowed law enforcement minimum taser used ape second stepped towards bat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.text[36709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e77567b4-ba80-4c85-bf22-6cd747131fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3060 Ti\n",
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060 Ti\n",
      "tensor([2., 4., 6.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# # Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")  # Use GPU\n",
    "#     print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "#     print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "# print(torch.cuda.device_count())  # Number of GPUs available\n",
    "# print(torch.cuda.get_device_name(0))  # Name of the GPU\n",
    "\n",
    "# x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "# y = x * 2\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87346863-3db6-4a35-95d8-331bdc65b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# 0. GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1989a076-7003-445e-9e7d-18284364e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenization function\n",
    "def tokenize_data(texts, tokenizer, max_length=128):\n",
    "    if isinstance(texts, list):\n",
    "        texts = [str(text) if text is not None else \"\" for text in texts]\n",
    "    else:\n",
    "        texts = str(texts) if texts is not None else \"\"\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0513cc-6150-45ab-86a9-ba19052cf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and preprocess datasets for training\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    final_data[\"text\"].tolist(),\n",
    "    final_data[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=final_data[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af52e83-f1ff-494e-9596-ef9cf8b0a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model_dir(base_path):\n",
    "    model_dirs = glob.glob(os.path.join(base_path, \"*\"))\n",
    "    if not model_dirs:\n",
    "        return None\n",
    "    latest_dir = max(model_dirs, key=os.path.getmtime)\n",
    "    return latest_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84d227-7af9-48fd-99f0-00d53e7dbab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c0501f-45b5-45b7-81e8-92844a6a8dbf",
   "metadata": {},
   "source": [
    "### Train Distilbert Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5756ffe-4eac-4556-8840-856e363c8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DistilBERT-based model\n",
    "def train_distilbert(train_texts, train_labels, test_texts, test_labels, epochs, batch_size, output_dir='./model/distilbert'):\n",
    "    print(\"Training DistilBERT\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=128)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=128)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels, dtype=torch.long)\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels, dtype=torch.long)\n",
    "    })\n",
    "\n",
    "    # Calculate dynamic steps\n",
    "    total_train_samples = len(train_texts)\n",
    "    print(f\"total_train_samples: {total_train_samples}\")\n",
    "    steps_per_epoch = math.ceil(total_train_samples / batch_size)\n",
    "    print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "    eval_steps = 7 * steps_per_epoch // 100  # Evaluate every ~7% of an epoch \n",
    "\n",
    "    print(f\"Total train samples: {total_train_samples}\")\n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"Eval steps: {eval_steps}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps ,  \n",
    "        save_steps= 8 * eval_steps,  \n",
    "        gradient_accumulation_steps=2,  \n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,  # L2 regularization\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_steps=int(0.1 * steps_per_epoch),  # 10% warmup steps\n",
    "        logging_dir='./distilbert_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        no_cuda=False,  # Ensure GPU usage\n",
    "        dataloader_num_workers=2  \n",
    "    )\n",
    "\n",
    "    # Compute metrics function\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    # Initialize Trainer with EarlyStoppingCallback\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],  # Early stopping\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    print(f\"DistilBERT model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ccea91-fd26-4d8c-8c15-004a9e0da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilBERT model\n",
    "def load_distilbert():\n",
    "    print(f\"Loading DistilBERT model from {DISTILBERT_PATH}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(DISTILBERT_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(DISTILBERT_PATH)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cfd1c-d455-4476-aea3-033adc4f75da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a226ad-4604-4250-abb6-af54a0c65784",
   "metadata": {},
   "source": [
    "### Train GPT-2 Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0971f7-15ed-4664-8a42-fff2cb88c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt2(train_texts, test_texts, epochs, batch_size):\n",
    "    print(\"Training distilgpt2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a padding token, using EOS token\n",
    "    config = GPT2Config.from_pretrained(\"distilgpt2\")\n",
    "    config.attn_pdrop = 0.2  \n",
    "    config.resid_pdrop = 0.2  \n",
    "    model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", config=config).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenizer(\n",
    "        train_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    )\n",
    "    test_encodings = tokenizer(\n",
    "        test_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Set the labels to be the same as input IDs for causal language modeling\n",
    "    train_encodings['labels'] = train_encodings['input_ids'].clone()\n",
    "    test_encodings['labels'] = test_encodings['input_ids'].clone()\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['labels'],\n",
    "    })\n",
    "\n",
    "    # Calculate dynamic steps\n",
    "    total_train_samples = len(train_texts)\n",
    "    print(f\"total_train_samples: {total_train_samples}\")\n",
    "    steps_per_epoch = math.ceil(total_train_samples / batch_size)\n",
    "    print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "    eval_steps = math.ceil(0.20 * steps_per_epoch)  # Evaluate every ~7% of an epoch\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(GPT2_PATH, f\"gpt2_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        # per_device_train_batch_size=batch_size,\n",
    "        # per_device_eval_batch_size=batch_size,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",  \n",
    "        eval_steps=eval_steps,  \n",
    "        save_steps= 3 * eval_steps,  \n",
    "        gradient_accumulation_steps=2,  \n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        warmup_steps=int(0.1 * steps_per_epoch),  # Warm-up for 10% of steps\n",
    "        logging_dir='./gpt2_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",  \n",
    "        greater_is_better=False,  # Loss should decrease\n",
    "        fp16=torch.cuda.is_available(),  \n",
    "        dataloader_num_workers=2,  \n",
    "    )\n",
    "\n",
    "    # Initialize Trainer with EarlyStoppingCallback\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],  # Stop after 4 evaluations without improvement\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"GPT-2 model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "604ec3b1-9f9a-4f09-afff-01dd8f0df3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest GPT-2 model\n",
    "def load_gpt2():\n",
    "    try:\n",
    "        model_dirs = [\n",
    "            os.path.join(GPT2_PATH, d) for d in os.listdir(GPT2_PATH) if d.startswith(\"gpt2_\")\n",
    "        ]\n",
    "        if not model_dirs:\n",
    "            raise FileNotFoundError(f\"No directories starting with 'gpt2_' found in {GPT2_PATH}\")\n",
    "        \n",
    "        latest_path = max(model_dirs, key=os.path.getmtime)\n",
    "\n",
    "        print(f\"Attempting to load the latest GPT-2 model from: {latest_path}\")\n",
    "\n",
    "        # Load the model and tokenizer\n",
    "        model = AutoModelForCausalLM.from_pretrained(latest_path).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_path)\n",
    "\n",
    "        print(f\"Successfully loaded GPT-2 model and tokenizer from {latest_path}\")\n",
    "\n",
    "        return model, tokenizer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GPT-2 model: {str(e)}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55f1fbf2-201b-4f88-af71-37569dcdb188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the latest GPT-2 model from: ./model/gpt2\\gpt2_20241126_154614\n",
      "Successfully loaded GPT-2 model and tokenizer from ./model/gpt2\\gpt2_20241126_154614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model, gpt2_tokenizer = load_gpt2()\n",
    "gpt2_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074e863-3e66-413b-8883-477a7afab7f0",
   "metadata": {},
   "source": [
    "### Train ELECTRA Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1509265a-3b07-4168-8206-316a11d996a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELECTRA Training Function\n",
    "def train_electra(train_texts, train_labels, test_texts, test_labels, epochs, batch_size):\n",
    "    print(\"Training ELECTRA\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=2).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=128)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=128)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels, dtype=torch.long)\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels, dtype=torch.long)\n",
    "    })\n",
    "\n",
    "    # Calculate dynamic steps\n",
    "    total_train_samples = len(train_texts)\n",
    "    print(f\"total_train_samples: {total_train_samples}\")\n",
    "    steps_per_epoch = math.ceil(total_train_samples / batch_size)\n",
    "    print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "    eval_steps = math.ceil(0.10 * steps_per_epoch)\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(ELECTRA_PATH, f\"electra_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps ,  \n",
    "        save_steps=5 * eval_steps,  \n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,  # L2 regularization\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_steps=int(0.1 * steps_per_epoch),  # 10% of steps for warmup\n",
    "        logging_dir='./electra_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        no_cuda=False,# Ensure GPU-only\n",
    "        dataloader_num_workers=2\n",
    "    )\n",
    "\n",
    "    # Define compute metrics function\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    # Initialize the Trainer with EarlyStoppingCallback\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"ELECTRA model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c44f0b6f-840c-4469-8c61-d9b341846504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_electra():\n",
    "    print(\"Loading the latest ELECTRA model...\")\n",
    "    checkpoint_dirs = [\n",
    "        os.path.join(ELECTRA_PATH, d) for d in os.listdir(ELECTRA_PATH) if d.startswith(\"electra_\")\n",
    "    ]\n",
    "    if not checkpoint_dirs:\n",
    "        raise FileNotFoundError(f\"No ELECTRA checkpoints found in {ELECTRA_PATH}\")\n",
    "\n",
    "    latest_checkpoint = max(checkpoint_dirs, key=os.path.getmtime)\n",
    "    print(f\"Latest checkpoint directory found: {latest_checkpoint}\")\n",
    "\n",
    "    # Load the model and tokenizer from the latest checkpoint\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(latest_checkpoint).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_checkpoint)\n",
    "        print(f\"ELECTRA model and tokenizer loaded successfully from {latest_checkpoint}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to load ELECTRA model from {latest_checkpoint}. Error: {str(e)}\"\n",
    "        )\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a488d6e-91d5-4c77-98eb-c565ad2c69f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the latest ELECTRA model...\n",
      "Latest checkpoint directory found: ./model/electra\\electra_20241126_172853\n",
      "ELECTRA model and tokenizer loaded successfully from ./model/electra\\electra_20241126_172853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra_model, electra_tokenizer = load_electra()\n",
    "electra_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f51431-a57e-4a5a-85d6-aab19c4b1ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e89e989-aa53-481a-a911-6fde2fa29315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLAMA Training Function\n",
    "# Public LLAMA model training function\n",
    "def train_llama(train_texts, test_texts, epochs):\n",
    "    # print(\"Training LLAMA\")\n",
    "    # token = \"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\"  # Replace with your actual Hugging Face token\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "    # model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer, max_length=64)\n",
    "    test_encodings = tokenize_data(test_texts, tokenizer, max_length=64)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(LLAMA_PATH, f\"llama_{timestamp}\")\n",
    "\n",
    "    # Define training arguments for CPU usage\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        logging_dir='./llama_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=True,  # Ensure CPU usage\n",
    "        bf16=False,  # Set to False for CPU training\n",
    "        dataloader_num_workers=3\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"LLAMA model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c852e8f4-05d6-4a2f-a385-06b7d21abca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest LLAMA model\n",
    "def load_llama():\n",
    "    model = AutoModelForCausalLM.from_pretrained(LLAMA_PATH).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLAMA_PATH)\n",
    "    print(f\"LLAMA model loaded from {LLAMA_PATH}\")\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34191d-9902-4a4f-b578-1578fd6b1757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e70e9ff5-f77c-4d95-87d5-1cb935b5c324",
   "metadata": {},
   "source": [
    "### Train Opt  Classifier Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de9783be-4543-4e34-8681-970e796be284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_opt_classifier(train_texts, train_labels, test_texts, test_labels, epochs, batch_size):\n",
    "    print(\"Training OPT as a Classifier\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"facebook/opt-125m\", num_labels=2).to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenizer(\n",
    "        train_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    )\n",
    "    test_encodings = tokenizer(\n",
    "        test_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(train_labels)\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': torch.tensor(test_labels)\n",
    "    })\n",
    "\n",
    "    # Calculate dynamic steps\n",
    "    total_train_samples = len(train_texts)\n",
    "    print(f\"total_train_samples: {total_train_samples}\")\n",
    "    steps_per_epoch = math.ceil(total_train_samples / batch_size)\n",
    "    print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "    eval_steps = math.ceil(0.10 * steps_per_epoch)  # Evaluate every ~7% of an epoch\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(OPT_PATH, f\"opt_classifier_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_steps=3 * eval_steps,  # Save the model every evaluation 56%\n",
    "        gradient_accumulation_steps=2,  \n",
    "        learning_rate=3e-5,  \n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_steps=int(0.1 * steps_per_epoch),  # Warm-up 10% of steps\n",
    "        logging_dir='./opt_classifier_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        no_cuda=False, # Ensure GPU usage\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        dataloader_num_workers=2\n",
    "    )\n",
    "\n",
    "    # Define evaluation metrics\n",
    "    def compute_metrics(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],  # Stop after 5 evaluations without improvement\n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"OPT Classifier model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c29e17f-1104-4eef-aee6-8e982cfefc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opt_classifier():\n",
    "    try:\n",
    "        model_dirs = [\n",
    "            os.path.join(OPT_PATH, d) for d in os.listdir(OPT_PATH) if d.startswith(\"opt_classifier_\")\n",
    "        ]\n",
    "        if not model_dirs:\n",
    "            raise FileNotFoundError(f\"No directories starting with 'opt_classifier_' found in {OPT_PATH}\")\n",
    "\n",
    "        latest_path = max(model_dirs, key=os.path.getmtime)\n",
    "\n",
    "        print(f\"Attempting to load the latest OPT Classifier model from: {latest_path}\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(latest_path).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_path)\n",
    "\n",
    "        print(f\"Successfully loaded OPT Classifier model and tokenizer from {latest_path}\")\n",
    "\n",
    "        return model, tokenizer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading OPT Classifier model: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c804e649-54ef-4f57-ad70-b2ae53fec421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the latest OPT Classifier model from: ./model/opt\\opt_classifier_20241126_133043\n",
      "Successfully loaded OPT Classifier model and tokenizer from ./model/opt\\opt_classifier_20241126_133043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_classifier_model, opt_classifierr_tokenizer = load_opt_classifier()\n",
    "opt_classifier_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14545c72-da33-4b5a-b541-36798fdc848b",
   "metadata": {},
   "source": [
    "### Train Opt Generator Model over ISOT_Fake_News_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63f63f86-f143-4996-9028-a6296e432a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_opt_generator(train_texts, test_texts, epochs, batch_size):\n",
    "    print(\"Training OPT as a Generator\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\").to(device)\n",
    "\n",
    "    # Tokenize training and testing data\n",
    "    train_encodings = tokenizer(train_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    test_encodings = tokenizer(test_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    eval_dataset = Dataset.from_dict({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': test_encodings['input_ids']\n",
    "    })\n",
    "\n",
    "    # Calculate dynamic steps\n",
    "    total_train_samples = len(train_texts)\n",
    "    print(f\"total_train_samples: {total_train_samples}\")\n",
    "    steps_per_epoch = math.ceil(total_train_samples / batch_size)\n",
    "    print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "    eval_steps = math.ceil(0.07 * steps_per_epoch)  # Evaluate every ~7% of an epoch\n",
    "\n",
    "\n",
    "    # Set output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(OPT_PATH, f\"opt_generator_{timestamp}\")\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",  \n",
    "        eval_steps=eval_steps, \n",
    "        save_steps= 8 * eval_steps,  \n",
    "        gradient_accumulation_steps=2,  \n",
    "        learning_rate=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_steps=int(0.1* steps_per_epoch),  \n",
    "        logging_dir='./opt_generator_logs',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",\n",
    "        greater_is_better=False,\n",
    "        no_cuda=False, # Ensure GPU usage\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        dataloader_num_workers=2\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  \n",
    "    )\n",
    "\n",
    "    # Train and save the model\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"OPT Generator model saved to {output_dir}\")\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e13564fa-10a3-4077-81be-5c30177a8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opt_generator():\n",
    "    try:\n",
    "        # List all directories in the OPT_PATH that match the naming convention\n",
    "        model_dirs = [\n",
    "            os.path.join(OPT_PATH, d) for d in os.listdir(OPT_PATH) if d.startswith(\"opt_generator_\")\n",
    "        ]\n",
    "        if not model_dirs:\n",
    "            raise FileNotFoundError(f\"No directories starting with 'opt_generator_' found in {OPT_PATH}\")\n",
    "\n",
    "        # Find the latest model directory by modification time\n",
    "        latest_path = max(model_dirs, key=os.path.getmtime)\n",
    "\n",
    "        print(f\"Attempting to load the latest OPT Generator model from: {latest_path}\")\n",
    "\n",
    "        # Load the model and tokenizer from the latest directory\n",
    "        model = AutoModelForCausalLM.from_pretrained(latest_path).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(latest_path)\n",
    "\n",
    "        print(f\"Successfully loaded OPT Generator model and tokenizer from {latest_path}\")\n",
    "\n",
    "        return model, tokenizer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading OPT Generator model: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29ff5ff2-7fde-4e64-b4e5-ef8865e57f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at ./model/opt\\opt_generator_20241126_155420 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the latest OPT Generator model from: ./model/opt\\opt_generator_20241126_155420\n",
      "Successfully loaded OPT Generator model and tokenizer from ./model/opt\\opt_generator_20241126_155420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_generator_model, opt_generator_tokenizer = load_opt_generator()\n",
    "opt_generator_model.to(device)\n",
    "opt_generator_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab65af0-b857-4c08-ac67-1980bab6779d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ee2113-da86-4ce2-8efe-3d9fd7092750",
   "metadata": {},
   "source": [
    "## Hybrid Detection Models for Robust Detection of Disinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30c031f3-b6bb-42dd-9d60-0910c397c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detection Model with DistilBERT and GPT-2\n",
    "def detect_with_distilbert_gpt2(text, bert_model, bert_tokenizer, gpt_model, gpt_tokenizer, similarity_threshold=0.77):\n",
    "    \n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # DistilBERT prediction\n",
    "    bert_inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
    "    bert_outputs = bert_model(input_ids=bert_inputs['input_ids'], attention_mask=bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    # GPT-2 text generation \n",
    "    gpt_inputs = gpt_tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True  \n",
    "    )\n",
    "    gpt_inputs = gpt_inputs.to(device)\n",
    "    gpt_outputs = gpt_model.generate(\n",
    "        gpt_inputs['input_ids'],\n",
    "        attention_mask=gpt_inputs['attention_mask'], \n",
    "        max_new_tokens=50, \n",
    "        pad_token_id=gpt_tokenizer.pad_token_id\n",
    "    )\n",
    "    generated_text = gpt_tokenizer.decode(gpt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # BERT prediction on GPT-2-generated text\n",
    "    generated_bert_inputs = bert_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
    "    generated_bert_outputs = bert_model(input_ids=generated_bert_inputs['input_ids'], attention_mask=generated_bert_inputs['attention_mask'], output_hidden_states=True)\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:, 0, :]  # [CLS] token embedding\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:, 0, :]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ae1e892-9bf1-4b64-b3b5-e1ed17a0860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_distilbert_opt(text, bert_model, bert_tokenizer, opt_model, opt_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # DistilBERT prediction\n",
    "    bert_inputs = bert_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=64\n",
    "    ).to(device)\n",
    "    bert_outputs = bert_model(\n",
    "        input_ids=bert_inputs['input_ids'],\n",
    "        attention_mask=bert_inputs['attention_mask'],\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    # OPT text generation using max_new_tokens\n",
    "    opt_inputs = opt_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=64\n",
    "    ).to(device)\n",
    "    opt_outputs = opt_model.generate(\n",
    "        opt_inputs['input_ids'],\n",
    "        attention_mask=opt_inputs['attention_mask'],\n",
    "        max_new_tokens=50,  \n",
    "        pad_token_id=opt_tokenizer.pad_token_id\n",
    "    )\n",
    "    generated_text = opt_tokenizer.decode(opt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # DistilBERT prediction on OPT-generated text\n",
    "    generated_bert_inputs = bert_tokenizer(\n",
    "        generated_text, return_tensors='pt', truncation=True, padding=True, max_length=64\n",
    "    ).to(device)\n",
    "    generated_bert_outputs = bert_model(\n",
    "        input_ids=generated_bert_inputs['input_ids'],\n",
    "        attention_mask=generated_bert_inputs['attention_mask'],\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    bert_embedding = bert_outputs.hidden_states[-1][:, 0, :]  # [CLS] token embedding\n",
    "    generated_bert_embedding = generated_bert_outputs.hidden_states[-1][:, 0, :]\n",
    "    similarity = torch.nn.functional.cosine_similarity(bert_embedding, generated_bert_embedding, dim=1).item()\n",
    "\n",
    "    if bert_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827af81-862f-43ac-ae2d-a15ea54be57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "342fe109-737f-49ee-998f-34f0f9071707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_distilbert_opt_generator(text, distilbert_model, distilbert_tokenizer, opt_generator_model, opt_generator_tokenizer, similarity_threshold=0.77):\n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # DistilBERT prediction\n",
    "    bert_inputs = distilbert_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "    bert_outputs = distilbert_model(\n",
    "        input_ids=bert_inputs['input_ids'],\n",
    "        attention_mask=bert_inputs['attention_mask'],\n",
    "        output_hidden_states=True  \n",
    "    )\n",
    "    bert_prediction = torch.argmax(bert_outputs.logits, dim=1).item()\n",
    "\n",
    "    # OPT Generator text generation using max_new_tokens\n",
    "    generator_inputs = opt_generator_tokenizer.encode_plus(\n",
    "        text, return_tensors='pt', max_length=128, truncation=True, padding=True\n",
    "    ).to(device)\n",
    "    generator_outputs = opt_generator_model.generate(\n",
    "        generator_inputs['input_ids'],\n",
    "        attention_mask=generator_inputs['attention_mask'],\n",
    "        max_new_tokens=50,  \n",
    "        pad_token_id=opt_generator_tokenizer.pad_token_id\n",
    "    )\n",
    "    generated_text = opt_generator_tokenizer.decode(generator_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # DistilBERT prediction on OPT-generated text\n",
    "    generated_bert_inputs = distilbert_tokenizer(\n",
    "        generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "    generated_bert_outputs = distilbert_model(\n",
    "        input_ids=generated_bert_inputs['input_ids'],\n",
    "        attention_mask=generated_bert_inputs['attention_mask'],\n",
    "        output_hidden_states=True  \n",
    "    )\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    original_embedding = bert_outputs.hidden_states[-1][:, 0, :]  # [CLS] token embedding\n",
    "    generated_embedding = generated_bert_outputs.hidden_states[-1][:, 0, :]  \n",
    "    similarity = torch.nn.functional.cosine_similarity(original_embedding, generated_embedding, dim=-1).item()\n",
    "\n",
    "    # Return detection result\n",
    "    if bert_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea243e1c-638f-4f91-ba1b-3fb77d186bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6b7c-eb09-41a4-9670-15c53b449972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_opt_classifier_opt_generator(text, opt_classifier_model, opt_classifier_tokenizer, opt_generator_model, opt_generator_tokenizer, similarity_threshold=0.77):\n",
    "    \n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # OPT Classifier prediction\n",
    "    classifier_inputs = opt_classifier_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "    classifier_outputs = opt_classifier_model(\n",
    "        input_ids=classifier_inputs['input_ids'],\n",
    "        attention_mask=classifier_inputs['attention_mask'],\n",
    "        output_hidden_states=True  # Ensure hidden states are returned\n",
    "    )\n",
    "    classifier_prediction = torch.argmax(classifier_outputs.logits, dim=1).item()\n",
    "\n",
    "    # OPT Generator text generation\n",
    "    generator_inputs = opt_generator_tokenizer.encode_plus(\n",
    "        text, return_tensors='pt', max_length=128, truncation=True, padding=True\n",
    "    ).to(device)\n",
    "    generator_outputs = opt_generator_model.generate(\n",
    "        generator_inputs['input_ids'],\n",
    "        attention_mask=generator_inputs['attention_mask'],\n",
    "        max_new_tokens=50,  # Generate 50 new tokens beyond the input\n",
    "        pad_token_id=opt_generator_tokenizer.pad_token_id\n",
    "    )\n",
    "    generated_text = opt_generator_tokenizer.decode(generator_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # OPT Classifier prediction on OPT-generated text\n",
    "    generated_classifier_inputs = opt_classifier_tokenizer(\n",
    "        generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "    generated_classifier_outputs = opt_classifier_model(\n",
    "        input_ids=generated_classifier_inputs['input_ids'],\n",
    "        attention_mask=generated_classifier_inputs['attention_mask'],\n",
    "        output_hidden_states=True  # Ensure hidden states are returned\n",
    "    )\n",
    "\n",
    "    # Ensure hidden states are available\n",
    "    if classifier_outputs.hidden_states is None or generated_classifier_outputs.hidden_states is None:\n",
    "        raise ValueError(\"Model outputs do not contain hidden states. Ensure output_hidden_states=True.\")\n",
    "\n",
    "    # Extract embeddings from the classifier model for cosine similarity\n",
    "    original_embedding = classifier_outputs.hidden_states[-1][:, 0, :]  # [CLS] token\n",
    "    generated_embedding = generated_classifier_outputs.hidden_states[-1][:, 0, :]\n",
    "    similarity = torch.nn.functional.cosine_similarity(original_embedding, generated_embedding, dim=-1).item()\n",
    "\n",
    "    # Decide based on classification and similarity\n",
    "    if classifier_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb52ce0-2ec8-468c-aa9a-97d013491757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7cf12-91b2-4011-b1b4-9ae1555c0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_opt_classifier_gpt2(text, opt_classifier_model, opt_classifier_tokenizer, gpt_model, gpt_tokenizer, similarity_threshold=0.77):\n",
    "    \n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # OPT Classifier prediction\n",
    "    classifier_inputs = opt_classifier_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
    "    classifier_outputs = opt_classifier_model(input_ids=classifier_inputs['input_ids'],attention_mask=classifier_inputs['attention_mask'])\n",
    "    classifier_prediction = torch.argmax(classifier_outputs.logits, dim=1).item()\n",
    "\n",
    "    # GPT-2 text generation\n",
    "    gpt_inputs = gpt_tokenizer.encode_plus(text, return_tensors='pt', max_length=128, truncation=True, padding=True).to(device)\n",
    "    gpt_outputs = gpt_model.generate(gpt_inputs['input_ids'],attention_mask=gpt_inputs['attention_mask'],max_new_tokens=50, pad_token_id=gpt_tokenizer.eos_token_id)\n",
    "    generated_text = gpt_tokenizer.decode(gpt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # OPT Classifier prediction on GPT-2-generated text\n",
    "    generated_classifier_inputs = opt_classifier_tokenizer(generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
    "    generated_classifier_outputs = opt_classifier_model(input_ids=generated_classifier_inputs['input_ids'],attention_mask=generated_classifier_inputs['attention_mask'])\n",
    "\n",
    "    # Cosine similarity between original and generated text logits\n",
    "    original_logits = classifier_outputs.logits[:, 1]  # Real News logits\n",
    "    generated_logits = generated_classifier_outputs.logits[:, 1]\n",
    "    similarity = torch.nn.functional.cosine_similarity(original_logits, generated_logits, dim=0).item()\n",
    "\n",
    "    if classifier_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca772e-dfcc-4072-8bd7-70d4c9c70641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0809f-180b-46d8-8214-7f0ee389f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_electra_gpt2(text, electra_model, electra_tokenizer, gpt2_model, gpt2_tokenizer, similarity_threshold=0.77):\n",
    "    \n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # ELECTRA prediction\n",
    "    electra_inputs = electra_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    electra_outputs = electra_model(\n",
    "        input_ids=electra_inputs['input_ids'],\n",
    "        attention_mask=electra_inputs['attention_mask'],\n",
    "        output_hidden_states=True  \n",
    "    )\n",
    "    electra_prediction = torch.argmax(electra_outputs.logits, dim=1).item()\n",
    "\n",
    "    # GPT-2 text generation \n",
    "    gpt_inputs = gpt2_tokenizer.encode_plus(\n",
    "        text, return_tensors='pt', max_length=128, truncation=True, padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    gpt_outputs = gpt2_model.generate(\n",
    "        gpt_inputs['input_ids'],\n",
    "        attention_mask=gpt_inputs['attention_mask'],\n",
    "        max_new_tokens=50,  \n",
    "        pad_token_id=gpt2_tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_text = gpt2_tokenizer.decode(gpt_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ELECTRA prediction on GPT-2-generated text\n",
    "    generated_electra_inputs = electra_tokenizer(\n",
    "        generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    generated_electra_outputs = electra_model(\n",
    "        input_ids=generated_electra_inputs['input_ids'],\n",
    "        attention_mask=generated_electra_inputs['attention_mask'],\n",
    "        output_hidden_states=True  \n",
    "    )\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    original_embedding = electra_outputs.hidden_states[-1][:, 0, :]  # [CLS] token embedding\n",
    "    generated_embedding = generated_electra_outputs.hidden_states[-1][:, 0, :]\n",
    "    similarity = torch.nn.functional.cosine_similarity(original_embedding, generated_embedding, dim=-1).item()\n",
    "\n",
    "    if electra_prediction == 0 or similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e4448-e7c8-45ba-88a3-09bad0ad3aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff281bfa-80b3-4cfb-bd8c-4ceb1c9dacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_electra_opt_generator(\n",
    "    text, electra_model, electra_tokenizer, opt_generator_model, opt_generator_tokenizer, similarity_threshold=0.77\n",
    "):\n",
    "    # Text preprocessing\n",
    "    text = preprocess_text(text)\n",
    "\n",
    "    # Electra prediction\n",
    "    electra_inputs = electra_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    electra_outputs = electra_model(\n",
    "        input_ids=electra_inputs['input_ids'],\n",
    "        attention_mask=electra_inputs['attention_mask'],\n",
    "        output_hidden_states=True,  # Ensure hidden states are returned\n",
    "    )\n",
    "\n",
    "    # OPT Generator text generation using max_new_tokens\n",
    "    generator_inputs = opt_generator_tokenizer(\n",
    "        text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    generator_outputs = opt_generator_model.generate(\n",
    "        generator_inputs['input_ids'],\n",
    "        attention_mask=generator_inputs['attention_mask'],\n",
    "        max_new_tokens=50,  # Specify the number of new tokens to generate\n",
    "        pad_token_id=opt_generator_tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    generated_text = opt_generator_tokenizer.decode(generator_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Electra prediction on OPT-generated text\n",
    "    generated_electra_inputs = electra_tokenizer(\n",
    "        generated_text, return_tensors='pt', truncation=True, padding=True, max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    generated_electra_outputs = electra_model(\n",
    "        input_ids=generated_electra_inputs['input_ids'],\n",
    "        attention_mask=generated_electra_inputs['attention_mask'],\n",
    "        output_hidden_states=True,  # Ensure hidden states are returned\n",
    "    )\n",
    "\n",
    "    # Cosine similarity between original and generated text embeddings\n",
    "    original_embedding = electra_outputs.hidden_states[-1][:, 0, :]  # [CLS] token embedding\n",
    "    generated_embedding = generated_electra_outputs.hidden_states[-1][:, 0, :]\n",
    "    similarity = torch.nn.functional.cosine_similarity(original_embedding, generated_embedding, dim=-1).item()\n",
    "\n",
    "    # Return detection result\n",
    "    if similarity < similarity_threshold:\n",
    "        return \"Fake News Detected.\"\n",
    "    else:\n",
    "        return \"Real News Detected.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5aa3b-ac24-414e-8afc-ce44d4e54417",
   "metadata": {},
   "source": [
    "## Train Models, distilbert, Gpt-2, LLama, Electra and Opt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941120b-8d49-46f6-b37b-f29f162a84f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training Phase\n",
    "bert_trainer, bert_model, bert_tokenizer = train_distilbert(train_texts, train_labels, test_texts, test_labels, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec6e85-a9fd-4e16-a1cf-e6f3b1315c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GPT-2 model\n",
    "torch.cuda.empty_cache()\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "#print(torch.cuda.memory_summary())\n",
    "gpt2_trainer, gpt2_model, gpt2_tokenizer = train_gpt2(train_texts, test_texts, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efce18-3ded-4857-943b-26cac47f337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LLAMA model\n",
    "llama_trainer, llama_model, llama_tokenizer = train_llama(train_texts, test_texts, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f9334-afe0-4355-a25d-67eedbf94a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ELECTRA model\n",
    "electra_trainer, electra_model, electra_tokenizer = train_electra(train_texts, train_labels, test_texts, test_labels, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117f380-529a-4d49-b5be-accc6895c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train OPT Classifier model\n",
    "opt_classifier_trainer, opt_classifier_model, opt_classifier_tokenizer = train_opt_classifier(train_texts, train_labels, test_texts, test_labels, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc35c3-b425-461c-b6ca-d55499fe5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train OPT Generator model\n",
    "opt_generator_trainer, opt_generator_model, opt_generator_tokenizer = train_opt_generator(train_texts, test_texts, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec085c2d-f02d-49dc-8412-c12607882cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b54398-81ed-4e11-a201-77d101ec3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate and save results \n",
    "def evaluate_and_save_results(test_texts, test_labels, detection_function, model_name, output_folder, *models_and_tokenizers):\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    real_count = 0\n",
    "    fake_count = 0\n",
    "    results = []\n",
    "\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "    # Evaluate each test case\n",
    "    for i, (text, label) in enumerate(zip(test_texts, test_labels)):\n",
    "        result = detection_function(text, *models_and_tokenizers)\n",
    "        is_real_detected = result == \"Real News Detected.\"\n",
    "        is_fake_detected = result == \"Fake News Detected.\"\n",
    "\n",
    "        if label == 1 and is_real_detected:  \n",
    "            real_count += 1\n",
    "        elif label == 0 and is_fake_detected: \n",
    "            fake_count += 1\n",
    "\n",
    "        results.append((f\"News {i+1}\", text, result, \"Real\" if label == 1 else \"Fake\"))\n",
    "\n",
    "    # Save the results\n",
    "    #results_file = os.path.join(output_folder, f\"{model_name}_results.txt\")\n",
    "    results_file = os.path.join(output_folder, f\"{model_name}_results.txt_SubmissionExample\")\n",
    "    with open(results_file, \"w\") as f:\n",
    "        for news_id, text, result, true_label in results:\n",
    "            f.write(f\"{news_id}: {result} (True Label: {true_label})\\n\")\n",
    "            f.write(f\"Text: {text}\\n\\n\")\n",
    "\n",
    "    # Save the accuracy counts\n",
    "    accuracy_file = os.path.join(output_folder, f\"{model_name}_accuracy.txt\")\n",
    "    with open(accuracy_file, \"w\") as f:\n",
    "        f.write(f\"Real Accuracy count: {real_count}/{len([l for l in test_labels if l == 1])}\\n\")\n",
    "        f.write(f\"Fake Accuracy count: {fake_count}/{len([l for l in test_labels if l == 0])}\\n\")\n",
    "        print(f\"Real Accuracy count: {real_count}/{len([l for l in test_labels if l == 1])}\\n\")\n",
    "        print(f\"Fake Accuracy count: {fake_count}/{len([l for l in test_labels if l == 0])}\\n\")\n",
    "\n",
    "    print(f\"Results and accuracy counts for {model_name} saved to {output_folder}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef6914-0022-4edf-8491-89edae6d7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select fixed numbers of true and false texts\n",
    "def select_test_data(test_texts, test_labels, num_true=15, num_false=15):\n",
    "    true_texts = [text for text, label in zip(test_texts, test_labels) if label == 1]\n",
    "    false_texts = [text for text, label in zip(test_texts, test_labels) if label == 0]\n",
    "\n",
    "    # Randomly sample the required number of true and false cases\n",
    "    selected_true = random.sample(true_texts, num_true)\n",
    "    selected_false = random.sample(false_texts, num_false)\n",
    "\n",
    "    selected_texts = selected_true + selected_false\n",
    "    selected_labels = [1] * num_true + [0] * num_false\n",
    "\n",
    "    return selected_texts, selected_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc23e6-f2f1-46c0-89d0-c45bb96fad10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e117fc-dde2-4b3c-acfe-37eea675f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and tokenizers\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.to(device)\n",
    "\n",
    "gpt2_model, gpt2_tokenizer = load_gpt2()\n",
    "gpt2_model.to(device)\n",
    "\n",
    "opt_classifier_model, opt_classifier_tokenizer = load_opt_classifier()\n",
    "opt_classifier_model.to(device)\n",
    "\n",
    "opt_generator_model, opt_generator_tokenizer = load_opt_generator()\n",
    "opt_generator_model.to(device)\n",
    "\n",
    "electra_model, electra_tokenizer = load_electra()\n",
    "electra_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da51f9a-371e-40fe-a9e2-41e59d8eba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of texts to evaluate\n",
    "balanced_num = 5\n",
    "NUM_TRUE = balanced_num \n",
    "NUM_FALSE = balanced_num  \n",
    "\n",
    "# Select fixed test data\n",
    "selected_test_texts, selected_test_labels = select_test_data(test_texts, test_labels, num_true=NUM_TRUE, num_false=NUM_FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c942b-4222-45ce-ade1-a7a0bc74a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT + OPT-Generator\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_distilbert_opt_generator,\n",
    "    \"distilbert_opt_generator\",\n",
    "    os.path.join(OUTPUT_DIR, \"distilbert_opt\"),\n",
    "    distilbert_model,\n",
    "    distilbert_tokenizer,\n",
    "    opt_generator_model,\n",
    "    opt_generator_tokenizer,\n",
    ")\n",
    "\n",
    "# For DistilBERT + GPT-2\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_distilbert_gpt2,\n",
    "    \"distilbert_gpt2\",\n",
    "    os.path.join(OUTPUT_DIR, \"distilbert_gpt2\"),\n",
    "    distilbert_model,\n",
    "    distilbert_tokenizer,\n",
    "    gpt2_model,\n",
    "    gpt2_tokenizer,\n",
    ")\n",
    "\n",
    "# For DistilBERT + OPT\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_distilbert_opt,\n",
    "    \"distilbert_opt\",\n",
    "    os.path.join(OUTPUT_DIR, \"distilbert_opt\"),\n",
    "    distilbert_model,\n",
    "    distilbert_tokenizer,\n",
    "    opt_generator_model,\n",
    "    opt_generator_tokenizer,\n",
    ")\n",
    "\n",
    "# For Electra + OPT-Generator\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_electra_opt_generator,\n",
    "    \"electra_Generator\",\n",
    "    os.path.join(OUTPUT_DIR, \"electra_opt\"),\n",
    "    electra_model,\n",
    "    electra_tokenizer,\n",
    "    opt_generator_model,\n",
    "    opt_generator_tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "# For Electra + GPT-2\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_electra_gpt2,\n",
    "    \"electra_gpt2\",\n",
    "    os.path.join(OUTPUT_DIR, \"electra_gpt2\"),\n",
    "    electra_model,\n",
    "    electra_tokenizer,\n",
    "    gpt2_model,\n",
    "    gpt2_tokenizer,\n",
    ")\n",
    "\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,  \n",
    "    selected_test_labels,  \n",
    "    detect_with_opt_classifier_opt_generator,  \n",
    "    \"opt_classifier_opt_generator\",  \n",
    "    os.path.join(OUTPUT_DIR, \"opt_classifier_opt_generator\"),  \n",
    "    opt_classifier_model,  \n",
    "    opt_classifier_tokenizer, \n",
    "    opt_generator_model,  \n",
    "    opt_generator_tokenizer  \n",
    ")\n",
    "\n",
    "# For OPT-Classifier + GPT-2\n",
    "evaluate_and_save_results(\n",
    "    selected_test_texts,\n",
    "    selected_test_labels,\n",
    "    detect_with_opt_classifier_gpt2,\n",
    "    \"opt_classifier_gpt2\",\n",
    "    os.path.join(OUTPUT_DIR, \"opt_classifier_gpt2\"),\n",
    "    opt_classifier_model,\n",
    "    opt_classifier_tokenizer,\n",
    "    gpt2_model,\n",
    "    gpt2_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86359625-a7bf-4d33-bb81-c7d04c04e0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a2bd33-6cd6-43e8-9337-decd7bbc1796",
   "metadata": {},
   "source": [
    "# Model Evaluation Under Outside Data(Buzzfeed) - Of One Model (distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31ff9ae2-902a-466c-a946-a8da3e72013f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>posted frank wilkenmeyer 25 sep 2016 tell man ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "153  posted frank wilkenmeyer 25 sep 2016 tell man ...      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BuzzFeed datasets\n",
    "buzzfeed_real_df = pd.read_csv('./data/BuzzFeed_real_news_content.csv')\n",
    "buzzfeed_fake_df = pd.read_csv('./data/BuzzFeed_fake_news_content.csv')\n",
    "\n",
    "# Add 'label' column: 1 for real news, 0 for fake news\n",
    "buzzfeed_real_df['label'] = 1\n",
    "buzzfeed_fake_df['label'] = 0\n",
    "\n",
    "# Retain only relevant columns ('title', 'text', 'label') and drop rows with missing text\n",
    "buzzfeed_real_df = buzzfeed_real_df[['text', 'label']].dropna(subset=['text'])\n",
    "buzzfeed_fake_df = buzzfeed_fake_df[['text', 'label']].dropna(subset=['text'])\n",
    "\n",
    "# Combine real and fake datasets into one\n",
    "buzzfeed_combined_df = pd.concat([buzzfeed_real_df, buzzfeed_fake_df], ignore_index=True)\n",
    "# Apply preprocessing to 'text' column\n",
    "buzzfeed_combined_df['text'] = buzzfeed_combined_df['text'].apply(preprocess_text)\n",
    "# Display the cleaned data\n",
    "buzzfeed_combined_df.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d90d33-9a13-47a7-a57e-9d3bf3f14cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    "    matthews_corrcoef,\n",
    "    cohen_kappa_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eeacea9f-af1a-430d-bb46-eeed7568adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DistilBERT model from ./model/distilbert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Detection Phase\n",
    "# Load trained models and tokenizers\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9664ab0d-8cd4-4954-8b08-ae7af1006a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the latest OPT Classifier model from: ./model/opt\\opt_classifier_20241126_133043\n",
      "Successfully loaded OPT Classifier model and tokenizer from ./model/opt\\opt_classifier_20241126_133043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_classifier_model, opt_classifier_tokenizer = load_opt_classifier()\n",
    "opt_classifier_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ad4a990-f845-40de-8ba3-2b0bae552f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the latest ELECTRA model...\n",
      "Latest checkpoint directory found: ./model/electra\\electra_20241121_041552\n",
      "Using the checkpoint subdirectory: ./model/electra\\electra_20241121_041552\\checkpoint-2652\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load ELECTRA model from ./model/electra\\electra_20241121_041552\\checkpoint-2652. Error: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./model/electra\\electra_20241121_041552\\checkpoint-2652.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 27\u001b[0m, in \u001b[0;36mload_electra\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(latest_checkpoint)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(latest_checkpoint)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\transformers\\modeling_utils.py:3763\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   3764\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3765\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3766\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3767\u001b[0m         )\n\u001b[0;32m   3768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./model/electra\\electra_20241121_041552\\checkpoint-2652.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m electra_model, electra_tokenizer \u001b[38;5;241m=\u001b[39m load_electra()\n\u001b[0;32m      2\u001b[0m electra_model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[78], line 31\u001b[0m, in \u001b[0;36mload_electra\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mELECTRA model and tokenizer loaded successfully from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load ELECTRA model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_checkpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m     )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to load ELECTRA model from ./model/electra\\electra_20241121_041552\\checkpoint-2652. Error: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./model/electra\\electra_20241121_041552\\checkpoint-2652."
     ]
    }
   ],
   "source": [
    "electra_model, electra_tokenizer = load_electra()\n",
    "electra_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6dc92f-0a1c-46e0-b131-04ab3f642c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7017511b-3d15-4049-aad3-f3ff4bc14d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for evaluation\n",
    "texts = buzzfeed_combined_df['text'].tolist()\n",
    "labels = buzzfeed_combined_df['label'].tolist()\n",
    "\n",
    "# Store predictions and probabilities for evaluation\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# Run inference on each sample\n",
    "with torch.no_grad():\n",
    "    for text in texts:\n",
    "        # Tokenize and get model predictions\n",
    "        inputs = distilbert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64).to(device)\n",
    "        outputs = distilbert_model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_label = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "        predictions.append(predicted_label)\n",
    "        probabilities.append(probs.cpu().numpy()[0][1])  # Probability of class 1 (real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1feca1e-1a21-4a0a-ae74-913bdac7af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buzzfeed_Evaluation Metrics:\n",
      "Buzzfeed_Log Loss: 0.9132\n",
      "Buzzfeed_Brier Score Loss: 0.2466\n",
      "Buzzfeed_Matthews Correlation Coefficient: 0.4330\n",
      "Buzzfeed_Cohen's Kappa Score: 0.3956\n",
      "Buzzfeed_ROC AUC Score: 0.8530\n",
      "Buzzfeed_Accuracy Score: 0.6978\n",
      "Evaluation complete. Metrics and plots saved to: ./outputs/distilbert_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:171: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax_.legend(loc=\"lower right\")\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays for compatibility with metrics functions\n",
    "y_true = np.array(labels)\n",
    "y_pred = np.array(predictions)\n",
    "y_prob = np.array(probabilities)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "metrics_log = {\n",
    "    \"Buzzfeed_Log Loss\": log_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Brier Score Loss\": brier_score_loss(y_true, y_prob),\n",
    "    \"Buzzfeed_Matthews Correlation Coefficient\": matthews_corrcoef(y_true, y_pred),\n",
    "    \"Buzzfeed_Cohen's Kappa Score\": cohen_kappa_score(y_true, y_pred),\n",
    "    \"Buzzfeed_ROC AUC Score\": roc_auc_score(y_true, y_prob),\n",
    "    \"Buzzfeed_Accuracy Score\": accuracy_score(y_true, y_pred),\n",
    "}\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Print the metrics log\n",
    "print(\"Buzzfeed_Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Generate and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title(\"ROC Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_roc_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Generate and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title(\"Precision-Recall Curve - Buzzfeed_DistilBERT Only\")\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', \"Buzzfeed_precision_recall_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Summarize metrics in a DataFrame for quick inspection if needed\n",
    "metrics_df = pd.DataFrame(metrics_log, index=[0])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"Buzzfeed_metrics_summary.csv\"), index=False)\n",
    "\n",
    "print(\"Evaluation complete. Metrics and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e652dc1-fea1-4463-af0f-11572f915c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\AppData\\Local\\Temp\\ipykernel_34164\\3778630617.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_data = test_data.groupby('label', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1447 test cases from the test dataset.\n",
      "Distribution of sampled labels:\n",
      "label\n",
      "0    744\n",
      "1    703\n",
      "Name: count, dtype: int64\n",
      "Loading DistilBERT model from ./model/distilbert\n",
      "Evaluating DistilBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:171: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax_.legend(loc=\"lower right\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete for DistilBERT. Metrics, logs, and plots saved to: ./outputs/distilbert_only\n",
      "Attempting to load the latest OPT Classifier model from: ./model/opt\\opt_classifier_20241126_133043\n",
      "Successfully loaded OPT Classifier model and tokenizer from ./model/opt\\opt_classifier_20241126_133043\n",
      "Evaluating OPT...\n",
      "Evaluation complete for OPT. Metrics, logs, and plots saved to: ./outputs/opt_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\anaconda3\\envs\\IR_2024\\Lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:171: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax_.legend(loc=\"lower right\")\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "# Function to sample a subset of test data\n",
    "def sample_test_data(test_texts, test_labels, fraction=0.1, random_state=42):\n",
    "    test_data = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "    sampled_data = test_data.groupby('label', group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=fraction, random_state=random_state)\n",
    "    )\n",
    "    # Print the number of test cases sampled\n",
    "    total_samples = len(sampled_data)\n",
    "    print(f\"Sampled {total_samples} test cases from the test dataset.\")\n",
    "    print(f\"Distribution of sampled labels:\\n{sampled_data['label'].value_counts()}\")\n",
    "\n",
    "    return sampled_data['text'].tolist(), sampled_data['label'].tolist()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model_name, model, tokenizer, test_texts, test_labels, output_dir):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Detection function\n",
    "    def detect(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        fake_prob = probs[0][0].item()\n",
    "        real_prob = probs[0][1].item()\n",
    "        prediction = 1 if real_prob >= 0.5 else 0\n",
    "        return prediction, real_prob\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    y_score = []\n",
    "\n",
    "    for text in test_texts:\n",
    "        pred_label, real_prob = detect(text)\n",
    "        y_pred.append(pred_label)\n",
    "        y_score.append(real_prob)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    log_loss_value = log_loss(y_true, y_score)\n",
    "    brier_score = brier_score_loss(y_true, y_score)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "    # Log metrics\n",
    "    metrics_log = {\n",
    "        \"Log Loss\": log_loss_value,\n",
    "        \"Brier Score Loss\": brier_score,\n",
    "        \"Matthews Correlation Coefficient\": mcc,\n",
    "        \"Cohen's Kappa Score\": kappa,\n",
    "        \"ROC AUC Score\": roc_auc,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "    # Save metrics to log file\n",
    "    with open(os.path.join(output_dir, f\"{model_name}_metrics_log.txt\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "        for metric, value in metrics_log.items():\n",
    "            f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    metrics_df = pd.DataFrame(list(metrics_log.items()), columns=[\"Metric\", \"Score\"])\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f\"{model_name}_metrics_summary.csv\"), index=False)\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.savefig(os.path.join(output_dir, f\"{model_name}_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "    roc_display.plot()\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.savefig(os.path.join(output_dir, f\"{model_name}_roc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "    pr_display.plot()\n",
    "    plt.title(f'Precision-Recall Curve - {model_name}')\n",
    "    plt.savefig(os.path.join(output_dir, f\"{model_name}_precision_recall_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot metric overview\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metrics_log.keys(), metrics_log.values(), color='skyblue')\n",
    "    plt.title(f\"Metrics Overview - {model_name}\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{model_name}_metrics_overview.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Evaluation complete for {model_name}. Metrics, logs, and plots saved to: {output_dir}\")\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Sample the test data\n",
    "sampled_test_texts, sampled_test_labels = sample_test_data(test_texts, test_labels, fraction=0.1)\n",
    "\n",
    "# Models to Evaluate\n",
    "MODELS = {\n",
    "    \"DistilBERT\": load_distilbert,\n",
    "    \"OPT\": load_opt_classifier,\n",
    "    \"ELECTRA\": load_electra\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "OUTPUT_DIR = \"./outputs\"\n",
    "for model_name, loader_function in MODELS.items():\n",
    "    model, tokenizer = loader_function()\n",
    "    model.to(device)\n",
    "    evaluate_model(\n",
    "        model_name=model_name,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        test_texts=sampled_test_texts,\n",
    "        test_labels=sampled_test_labels,\n",
    "        output_dir=os.path.join(OUTPUT_DIR, f\"{model_name.lower()}_only\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff4bf4-d8c5-40f7-86a8-2139fbc208af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd8db39-3965-4794-97f0-a779c6e7f88b",
   "metadata": {},
   "source": [
    "# Model Evaluation Distilbert - Under Random Generation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a7cdb-bebf-4245-a98f-e11e541580c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection function using DistilBERT\n",
    "def detect_with_distilbert(text, model, tokenizer, threshold=0.5):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    fake_prob = probs[0][0].item()\n",
    "    real_prob = probs[0][1].item()\n",
    "    prediction = 1 if real_prob >= threshold else 0\n",
    "    return prediction, real_prob  # returning probability for ROC and PR curves\n",
    "\n",
    "\n",
    "test_text=\"Cop Shares Racist Meme About Michelle Obama; Now That Cop Is Having A VERY Bad Day (IMAGES)After the election of Donald Trump many folks seem to see it as a permission slip to be as racist and vile as possible. However, here s the thing, you re still going to get called out as racist and vile. And one Alabama police officer just found this out the hard way.According to the Washington Post: Talladega Police Officer Joel Husk was terminated Wednesday for violating the department s social media and code of conduct policies, City Manager Patrick Bryant said. What did he do? So glad you asked: Husk had posted several memes on his Facebook page, including one showing Obama and Melania Trump.  Fluent in Slovenian, English, French, Serbian, and German,  it said over Trump s photo. Over Obama s, it read:  Fluent in Ghetto. Not only that, he posted several extraordinarily racist memes:via Washington Postvia Washington PostAccording to the City Manager, the statements were  deemed to be biased or racially insensitive or derogatory  and because of that, they  have to take action to correct it. If you re going to be a police officer and serve all the public, you can t assume black people standing up for their rights are equivalent to the KKK. That s about the most horrific equivalence imaginable.Also, according to WaPo: Husk, 37, who had been with the department for about two and a half years, had also shared a meme showing President Obama with the words:  Was Dallas a terrorist attack? Yes! Carried out by Obama s own homegrown terrorist group! Which is a blatant lie and anyone who were to feel that way belongs nowhere near law enforcement. The city took the proper action letting this racist cop go, and hopefully it will be an example to police departments all over the country that this sort of behavior simply cannot be tolerated.Trump s election must not be allowed to serve as a permission slip to bigots everywhere that it s fine to be as awful as possible, because here in the land of the free and the home of the brave, everyone is protected. Everyone, regardless of color, class, gender, sexual orientation, or creed.Featured Photo by Chip Somodevilla/Getty Images'\"\n",
    "\n",
    "# Initialize DistilBERT model and tokenizer\n",
    "device = torch.device(\"cpu\")\n",
    "distilbert_model, distilbert_tokenizer = load_distilbert()\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Predict and print result for custom data\n",
    "result, real_prob = detect_with_distilbert(test_text, distilbert_model, distilbert_tokenizer)\n",
    "print(f\"Prediction for custom data: {result} (Real News Probability: {real_prob:.2f})\")\n",
    "\n",
    "if result == 0:\n",
    "    print(\"News is Fake\")\n",
    "else:\n",
    "    print(\"News is Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12bee1-1638-4fab-b922-74b5c21fc6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8debe46c-5ba7-43ce-8163-e3f44f858afe",
   "metadata": {},
   "source": [
    "# Model Evaluiation Under Simpilar Trained Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba2155-1e6d-484f-879a-c02565d59d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('./outputs/distilbert_only', exist_ok=True)\n",
    "\n",
    "# Evaluate the model\n",
    "y_true = test_labels\n",
    "y_pred = []\n",
    "y_score = []\n",
    "\n",
    "# Run detection on test data\n",
    "for text in test_texts:\n",
    "    pred_label, real_prob = detect_with_distilbert(text, distilbert_model, distilbert_tokenizer)\n",
    "    y_pred.append(pred_label)\n",
    "    y_score.append(real_prob)  # For ROC and Precision-Recall curves\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "log_loss_value = log_loss(y_true, y_score)\n",
    "brier_score = brier_score_loss(y_true, y_score)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "# Log and save metrics\n",
    "metrics_log = {\n",
    "    \"ISOT_Fake_News_Dataset_Log Loss\": log_loss_value,\n",
    "    \"ISOT_Fake_News_Dataset_Brier Score Loss\": brier_score,\n",
    "    \"ISOT_Fake_News_Dataset_Matthews Correlation Coefficient\": mcc,\n",
    "    \"ISOT_Fake_News_Dataset_Cohen's Kappa Score\": kappa,\n",
    "    \"ISOT_Fake_News_Dataset_ROC AUC Score\": roc_auc,\n",
    "    \"ISOT_Fake_News_Dataset_Accuracy Score\": accuracy,\n",
    "    \"ISOT_Fake_News_Dataset_F1 Score\": f1\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"ISOT_Fake_News_Dataset Evaluation Metrics:\")\n",
    "for metric, value in metrics_log.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Save metrics log to file\n",
    "with open(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_log.txt\"), \"w\") as f:\n",
    "    for metric, value in metrics_log.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame(list(metrics_log.items()), columns=[\"Metric\", \"Score\"])\n",
    "metrics_df.to_csv(os.path.join('./outputs/distilbert_only', \"ISOT_Fake_News_Dataset_metrics_summary.csv\"), index=False)\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_confusion_matrix_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "roc_display.plot()\n",
    "plt.title('ROC Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_roc_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "pr_display.plot()\n",
    "plt.title('Precision-Recall Curve - ISOT_Fake_News_Dataset_DistilBERT')\n",
    "plt.savefig(os.path.join('./outputs/distilbert_only', 'ISOT_Fake_News_Dataset_precision_recall_curve_distilbert.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Evaluation complete. Metrics, logs, and plots saved to:\", './outputs/distilbert_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf4826-e872-4eb4-b81c-882d7a33020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0aa35a-4650-4bf2-9250-ede453d9ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load generation models\n",
    "gpt2_model, gpt2_tokenizer = load_gpt2()\n",
    "llama_model, llama_tokenizer = load_llama()\n",
    "opt_model, opt_tokenizer = load_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ed56e-f678-4c8b-9ba3-63218a4e13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models \n",
    "# models = {\n",
    "#     'distilbert_gpt2': (gpt2_model, gpt2_tokenizer, detect_with_distilbert_gpt2),\n",
    "#     'distilbert_llama': (llama_model, llama_tokenizer, detect_with_distilbert_llama),\n",
    "#     'distilbert_opt': (opt_model, opt_tokenizer, detect_with_distilbert_opt)\n",
    "# }\n",
    "\n",
    "# Dictionary to store models for detection\n",
    "models = {\n",
    "    'distilbert_gpt2': (gpt2_model, gpt2_tokenizer, detect_with_distilbert_gpt2),\n",
    "    'distilbert_electra': (electra_model, electra_tokenizer, detect_with_distilbert_electra),\n",
    "    'distilbert_opt': (opt_model, opt_tokenizer, detect_with_distilbert_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79a8ff-a1a8-45e8-a5ae-87aafac4a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data and labels\n",
    "test_data = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "# Initialize results dictionary to store metrics for each combination\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69d7c4-2619-46f6-a021-0810ff71b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (gen_model, gen_tokenizer, detect_func) in models.items():\n",
    "    print(f\"Running detection for: {name}\")\n",
    "\n",
    "    y_true = test_data['label'].values\n",
    "    y_pred = []\n",
    "    y_score = []  # Store similarity scores for ROC and Precision-Recall curves\n",
    "\n",
    "    # Perform detection on test data\n",
    "    for text in test_data['text']:\n",
    "        result = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        pred_label = 1 if result == \"Real News Detected.\" else 0\n",
    "        y_pred.append(pred_label)\n",
    "\n",
    "        # Get similarity score from the detection function\n",
    "        # Modify detect_func to return score alongside label\n",
    "        _, similarity_score = detect_func(text, distilbert_model, distilbert_tokenizer, gen_model, gen_tokenizer)\n",
    "        y_score.append(similarity_score)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    report = classification_report(y_true, y_pred, target_names=['Fake', 'Real'], output_dict=True)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_true, y_pred, target_names=['Fake', 'Real'])}\")\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real'])\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'confusion_matrix_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'roc_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot and save Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n",
    "    plt.title(f'Precision-Recall Curve - {name}')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, name, f'precision_recall_curve_{name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "for name, metrics in results.items():\n",
    "    pd.DataFrame(metrics).to_csv(os.path.join(OUTPUT_DIR, name, f\"{name}_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467601f-ff6c-4bfc-8d40-49a47ba02116",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee319e9-a075-4b8f-bc3b-1e5055a96fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
